<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <link rel="icon" href="/favicon.png">

  <title>
  Designing an in-memory LFU cache - tech-lessons.in
  </title>
  <meta name="description" content="I had been working on building an in-memory LFU cache (least frequently used cache), and now that it is done, I thought of writing about the building blocks of an LFU cache. This article shares the building blocks of an LFU cache along with the ideas from two research papers: BP-Wrapper and TinyLFU." />
  <meta name="author" content="Sarthak Makhija" />
  
     <meta property="og:image" content="/lfu-cache-title.webp" />
  <meta name="generator" content="Hugo 0.140.1"><link rel="stylesheet" href="/css/styles.css" />

  
  

  <meta property="og:url" content="//localhost:1313/en/blog/designing_lfu_cache/">
  <meta property="og:site_name" content="tech-lessons.in">
  <meta property="og:title" content="Designing an in-memory LFU cache">
  <meta property="og:description" content="I had been working on building an in-memory LFU cache (least frequently used cache), and now that it is done, I thought of writing about the building blocks of an LFU cache. This article shares the building blocks of an LFU cache along with the ideas from two research papers: BP-Wrapper and TinyLFU.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2023-05-26T00:00:00+00:00">
    <meta property="article:modified_time" content="2023-05-26T00:00:00+00:00">
    <meta property="article:tag" content="Cache">
    <meta property="article:tag" content="TinyLFU">
    <meta property="article:tag" content="CacheD">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Designing an in-memory LFU cache">
  <meta name="twitter:description" content="I had been working on building an in-memory LFU cache (least frequently used cache), and now that it is done, I thought of writing about the building blocks of an LFU cache. This article shares the building blocks of an LFU cache along with the ideas from two research papers: BP-Wrapper and TinyLFU.">

  
  <meta itemprop="name" content="Designing an in-memory LFU cache">
  <meta itemprop="description" content="I had been working on building an in-memory LFU cache (least frequently used cache), and now that it is done, I thought of writing about the building blocks of an LFU cache. This article shares the building blocks of an LFU cache along with the ideas from two research papers: BP-Wrapper and TinyLFU.">
  <meta itemprop="datePublished" content="2023-05-26T00:00:00+00:00">
  <meta itemprop="dateModified" content="2023-05-26T00:00:00+00:00">
  <meta itemprop="wordCount" content="4278">
  <meta itemprop="keywords" content="Cache,TinyLFU,CacheD">

  
</head>
<body class="dark:bg-gray-800 dark:text-white relative flex flex-col min-h-screen"><header class="container flex justify-between md:justify-between gap-4 flex-wrap p-6 mx-auto relative">
  <a href="//localhost:1313/en/" class="capitalize font-extrabold text-2xl">
    
    <img src="/logo.png" alt="tech-lessons.in" class="h-8 max-w-full" />
    
  </a>
  <button class="mobile-menu-button md:hidden">
    <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <line x1="4" y1="8" x2="20" y2="8" />
      <line x1="4" y1="16" x2="20" y2="16" />
    </svg>
  </button>
  <ul class="mobile-menu absolute z-10 px-6 pb-6 md:p-0 top-full left-0 w-full md:w-auto md:relative hidden md:flex flex-col md:flex-row items-end md:items-center gap-4 lg:gap-6 bg-white dark:bg-gray-800">

    
    <li><a href="/en/">Home</a></li>
    
    <li><a href="/en/blog">Blogs</a></li>
    
    <li><a href="/en/page/about/">About Me</a></li>
    
    <li><a href="/en/page/projects/">My projects</a></li>
    

    

    
    <li class="grid place-items-center">
      <span class="open-search inline-block cursor-pointer">
        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" stroke-width="1.5"
          stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <circle cx="10" cy="10" r="7" />
          <line x1="21" y1="21" x2="15" y2="15" />
        </svg>
      </span>
    </li>
    

    
  </ul>
</header>
<main class="flex-1">
  
  

  
  <div class="relative max-w-5xl mx-auto px-4">
    <img src="/lfu-cache-title.webp" class="rounded-lg shadow-sm w-full object-contain" />
    
    <figcaption class="font-extralight text-xs"><i>Background by Drift Shutterbug on Pexels</i></figcaption>
    
    
    <div class="absolute top-4 right-8 rounded shadow bg-white text-gray-900 dark:bg-gray-900 dark:text-white px-2 py-0.5">
      
  
    May 26, 2023
  


    </div>
    
  </div>
  

  <article class="prose lg:prose-lg mx-auto my-8 dark:prose-dark px-4 max-w-5xl">

    <h1 class="text-2xl font-bold mb-2">Designing an in-memory LFU cache</h1>
    
    <h5 class="text-sm flex items-center flex-wrap">
      <svg xmlns="http://www.w3.org/2000/svg" class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <rect x="4" y="5" width="16" height="16" rx="2" />
        <line x1="16" y1="3" x2="16" y2="7" />
        <line x1="8" y1="3" x2="8" y2="7" />
        <line x1="4" y1="11" x2="20" y2="11" />
        <rect x="8" y="15" width="2" height="2" />
      </svg>
      Posted on 
  
    May 26, 2023
  


      
        &nbsp;&bull;&nbsp;
      
      <svg xmlns="http://www.w3.org/2000/svg" class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <circle cx="12" cy="12" r="9" />
        <polyline points="12 7 12 12 15 15" />
      </svg>
      21&nbsp;minutes
      &nbsp;&bull;
      <svg xmlns="http://www.w3.org/2000/svg" class="mx-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <path d="M3 19a9 9 0 0 1 9 0a9 9 0 0 1 9 0" />
        <path d="M3 6a9 9 0 0 1 9 0a9 9 0 0 1 9 0" />
        <line x1="3" y1="6" x2="3" y2="19" />
        <line x1="12" y1="6" x2="12" y2="19" />
        <line x1="21" y1="6" x2="21" y2="19" />
      </svg>
      4278&nbsp;words
      
    </h5>
    

    <details id="TableOfContents" class="px-4 mt-4 bg-gray-100 dark:bg-gray-700 rounded toc">
    <summary class="flex items-center font-bold py-2 px-4 cursor-pointer justify-between select-none text-black dark:text-white">
      <span>Table of contents</span>
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-down" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
        <polyline points="6 9 12 15 18 9"></polyline>
     </svg>
    </summary>

    <ul class="mt-2 pb-4">
        

        
        <li>
        <a href="#lfu-cache">LFU cache</a>
        

        
        </li><li>
        <a href="#measuring-access-frequency">Measuring access frequency</a>
        

        
        </li><li>
        <a href="#storing-keyvalue-mapping">Storing key/value mapping</a>
        

        
        </li><li>
        <a href="#making-the-cache-memory-bound">Making the cache memory bound</a>
        

        
        </li><li>
        <a href="#admission-and-eviction-policy">Admission and eviction policy</a>
        

        
        </li><li>
        <a href="#introducing-bp-wrapper">Introducing BP-Wrapper</a>
        

        
        <ul>
            <li>
        <a href="#get">Get</a>
        

        
        </li><li>
        <a href="#put">Put</a>
        

        
        </li></ul>
      </li><li>
        <a href="#measuring-metrics">Measuring metrics</a>
        

        
        <ul>
            <li>
        <a href="#false-sharing">False sharing</a>
        

        
        </li></ul>
      </li><li>
        <a href="#measuring-cache-hit-ratio">Measuring cache-hit ratio</a>
        

        
        <ul>
            <li>
        <a href="#distribution-of-elements">Distribution of elements</a>
        

        
        </li></ul>
      </li><li>
        <a href="#code">Code</a>
        

        
        </li><li>
        <a href="#relevant-research-papers">Relevant research papers</a>
        

        
        </li><li>
        <a href="#references">References</a>
        </li></ul>
  </details>

    <p>I had been working on building an in-memory LFU cache (least frequently used cache) and now that it is done, I thought of writing about the building blocks of an LFU cache. This article shares the building blocks of an LFU cache along with the ideas from two research papers: <a href="https://dgraph.io/blog/refs/TinyLFU%20-%20A%20Highly%20Efficient%20Cache%20Admission%20Policy.pdf" target="_blank" rel="noopener">TinyLFU</a>
 and <a href="https://dgraph.io/blog/refs/bp_wrapper.pdf" target="_blank" rel="noopener">BP-Wrapper</a>
</p>
<p><a href="https://github.com/SarthakMakhija/cached" target="_blank" rel="noopener">CacheD</a>
 is the name of my cache, and it is inspired by <a href="https://github.com/dgraph-io/ristretto" target="_blank" rel="noopener">Ristretto</a>
.
I know <strong>CacheD</strong> is a very creative name. Thank you.</p>
<p>Let&rsquo;s get started.</p>
<h3 id="lfu-cache">LFU cache</h3>
<p>According to <a href="https://en.wikipedia.org/wiki/Least_frequently_used" target="_blank" rel="noopener">Wikipedia</a>
: Least Frequently Used (LFU) is a type of cache algorithm used to manage memory within a computer. The standard characteristics of this method involve the system <em>keeping track of the number of times a block is referenced in memory</em>. When the <em>cache is full</em> and requires more room the system will <em>purge</em> the item with the <em>lowest reference frequency</em>.</p>
<p>Let&rsquo;s now understand the building blocks of an LFU cache, starting with a way to measure the access frequency.</p>
<h3 id="measuring-access-frequency">Measuring access frequency</h3>
<p>All LFU caches need to maintain the access frequency for each key.
Storing the access frequency in a <code>HashMap</code>-like data structure would mean that the space used to store the frequency is directly proportional to the number of keys in the cache.
This is an opportunity to use a probabilistic data structure like <a href="https://tech-lessons.in/blog/count_min_sketch/" target="_blank" rel="noopener">count-min sketch</a>
 and make a trade-off between the accuracy of the access frequency and the space used to store the frequency.</p>
<blockquote>
<p>Count-min sketch (CM sketch) is a probabilistic data structure that estimates the frequency of events in a data stream.
It relies on hash functions to map events to frequencies, but unlike a hash table, it uses only <strong>sublinear space</strong> at the expense of over-counting some events due to hash collisions. The countâ€“min sketch was invented in 2003 by Graham Cormode and S. Muthu Muthukrishnan.</p>
</blockquote>
<p><strong>CacheD</strong> uses count-min sketch inside the abstraction <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/lfu/frequency_counter.rs" target="_blank" rel="noopener">FrequencyCounter</a>
 to store the frequency for each key.</p>
<p>Count-min sketch is represented as a D*W matrix, where D is the total number of hash functions (or depth) and W is the width or the number of counters per hash function.</p>
<div class="align-center">
    <img src="/countminsketch.png"/>
</div>
<p>The matrix is initialized with zero at the beginning. A count-min sketch can be represented with the following structure:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#ff79c6">#[repr(transparent)]</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">#[derive(Debug, PartialEq)]</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">struct</span> <span style="color:#50fa7b">Row</span>(<span style="color:#8be9fd;font-style:italic">Vec</span><span style="color:#ff79c6">&lt;</span><span style="color:#8be9fd">u8</span><span style="color:#ff79c6">&gt;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">const</span> ROWS: <span style="color:#8be9fd">usize</span> <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">4</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">pub</span>(<span style="color:#ff79c6">crate</span>) <span style="color:#ff79c6">struct</span> <span style="color:#50fa7b">FrequencyCounter</span> {
</span></span><span style="display:flex;"><span>    matrix: [Row; ROWS],
</span></span><span style="display:flex;"><span>    seeds: [<span style="color:#8be9fd">u64</span>; ROWS],
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">//initialize the matrix
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span><span style="color:#ff79c6">fn</span> <span style="color:#50fa7b">matrix</span>(total_counters: <span style="color:#50fa7b">TotalCounters</span>) -&gt; [Row; ROWS] {
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd;font-style:italic">let</span> total_counters <span style="color:#ff79c6">=</span> (total_counters <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">2</span>) <span style="color:#ff79c6">as</span> <span style="color:#8be9fd">usize</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd;font-style:italic">let</span> rows <span style="color:#ff79c6">=</span>
</span></span><span style="display:flex;"><span>        (<span style="color:#bd93f9">0</span><span style="color:#ff79c6">..</span>ROWS)
</span></span><span style="display:flex;"><span>            .map(<span style="color:#ff79c6">|</span>_index<span style="color:#ff79c6">|</span> Row(vec![<span style="color:#bd93f9">0</span>; total_counters]))
</span></span><span style="display:flex;"><span>            .collect::<span style="color:#ff79c6">&lt;</span><span style="color:#8be9fd;font-style:italic">Vec</span><span style="color:#ff79c6">&lt;</span>Row<span style="color:#ff79c6">&gt;&gt;</span>();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    rows.try_into().unwrap()
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We still need to decide on the number of counters. What should the number of counters be to get the closest access frequency estimate?</p>
<p>We can start with a simple theory. If an LFU cache contains N keys, we can keep N counters per hash function in the count-min sketch. However, we need to consider
hash conflicts.</p>
<p>Let&rsquo;s understand the logic of incrementing the access frequency of a key with the following pseudocode.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span>    <span style="color:#ff79c6">pub</span>(<span style="color:#ff79c6">crate</span>) <span style="color:#ff79c6">fn</span> <span style="color:#50fa7b">increment_access_for</span>(<span style="color:#ff79c6">&amp;</span>self, key: <span style="color:#50fa7b">Key</span>) {
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4">// 1) Iterate through all the rows (row = 0 to depth = D)
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>        <span style="color:#6272a4">// 2) Get the hash of the incoming key
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>        <span style="color:#6272a4">// 3) Perform `hash % self.total_counters` to identify the column index (with width = W)
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>        <span style="color:#6272a4">// 4) Increment the value at the identified column in the row R(i)
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    }
</span></span></code></pre></div><p>Keeping the counters (imagine them as the number of columns) the same as the number of keys in the cache would mean a higher error rate in the access frequency estimate (because of hash conflicts).</p>
<p>To keep the estimates from wavering (/overestimating) too much because of hash conflicts, we need to have <code>counters = K times the number of keys</code>. Any choice of K is an attempt at reducing the hash conflict
of keys in each row.</p>
<p><strong>CacheD</strong> proposes <code>K = 10</code> and does <a href="https://github.com/SarthakMakhija/cached/blob/main/benches/benchmarks/frequency_counter.rs" target="_blank" rel="noopener">performance benchmarks</a>
 with <code>K = 2</code> and <code>K = 10</code>.</p>
<p>We have a way of measuring the access frequency of each key. Let&rsquo;s understand a way to store the key/value mapping.</p>
<h3 id="storing-keyvalue-mapping">Storing key/value mapping</h3>
<p>We need a way to store the value by key. This is done by the <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/store/mod.rs" target="_blank" rel="noopener">Store</a>
 abstraction in Cached.
<code>Store</code> uses <a href="https://docs.rs/dashmap/latest/dashmap/" target="_blank" rel="noopener">DashMap</a>
, a concurrent associative array/hashmap.</p>
<p><code>DashMap</code> maintains an array named <code>shards</code>; each element is a <code>RwLock</code> to a <code>HashMap</code>. The <code>put</code> operation for a key identifies the <code>shard_index</code>, acquires a <code>write lock</code>
against that shard and writes to the <code>HashMap</code> in the identified shard.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#ff79c6">pub</span> <span style="color:#ff79c6">struct</span> <span style="color:#50fa7b">DashMap</span><span style="color:#ff79c6">&lt;</span>K, V, S <span style="color:#ff79c6">=</span> RandomState<span style="color:#ff79c6">&gt;</span> {
</span></span><span style="display:flex;"><span>    shards: <span style="color:#8be9fd;font-style:italic">Box</span><span style="color:#ff79c6">&lt;</span>[RwLock<span style="color:#ff79c6">&lt;</span>HashMap<span style="color:#ff79c6">&lt;</span>K, V, S<span style="color:#ff79c6">&gt;&gt;</span>]<span style="color:#ff79c6">&gt;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//code omitted
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>}
</span></span></code></pre></div><p>We are build our key/value mapping on top of <code>DashMap</code>. The following code represents <code>Store</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#ff79c6">pub</span>(<span style="color:#ff79c6">crate</span>) <span style="color:#ff79c6">struct</span> <span style="color:#50fa7b">Store</span><span style="color:#ff79c6">&lt;</span>Key, Value<span style="color:#ff79c6">&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">where</span> Key: <span style="color:#50fa7b">Hash</span> <span style="color:#ff79c6">+</span> <span style="color:#8be9fd;font-style:italic">Eq</span>, {
</span></span><span style="display:flex;"><span>    store: <span style="color:#50fa7b">DashMap</span><span style="color:#ff79c6">&lt;</span>Key, StoredValue<span style="color:#ff79c6">&lt;</span>Value<span style="color:#ff79c6">&gt;&gt;</span>,
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">pub</span> <span style="color:#ff79c6">struct</span> <span style="color:#50fa7b">StoredValue</span><span style="color:#ff79c6">&lt;</span>Value<span style="color:#ff79c6">&gt;</span> {
</span></span><span style="display:flex;"><span>    value: <span style="color:#50fa7b">Value</span>,
</span></span><span style="display:flex;"><span>    key_id: <span style="color:#50fa7b">KeyId</span>,
</span></span><span style="display:flex;"><span>    expire_after: <span style="color:#8be9fd;font-style:italic">Option</span><span style="color:#ff79c6">&lt;</span>ExpireAfter<span style="color:#ff79c6">&gt;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">pub</span>(<span style="color:#ff79c6">crate</span>) is_soft_deleted: <span style="color:#8be9fd">bool</span>,
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>There is another decision to be made here.</p>
<p>How should we return the value to the clients as a part of the <code>get</code> operation?</p>
<ul>
<li>Option 1: return a reference of the value</li>
<li>Option 2: force the clients to provide a cloneable value as a part of the <code>put</code> operation and return <code>Some&lt;Value&gt;</code> by cloning the value, if it exists for the key</li>
<li>Option 3: provide both options</li>
</ul>
<p>Let&rsquo;s look at Option 1 first. To return a reference to the value, we need to look into the <code>get</code> method of <code>DashMap</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#ff79c6">pub</span> <span style="color:#ff79c6">fn</span> <span style="color:#50fa7b">get</span><span style="color:#ff79c6">&lt;</span>Q<span style="color:#ff79c6">&gt;</span>(<span style="color:#ff79c6">&amp;</span><span style="color:#50fa7b">&#39;a</span> self, key: <span style="color:#ff79c6">&amp;</span><span style="color:#50fa7b">Q</span>) -&gt; <span style="color:#8be9fd;font-style:italic">Option</span><span style="color:#ff79c6">&lt;</span>Ref<span style="color:#ff79c6">&lt;</span><span style="color:#50fa7b">&#39;a</span>, K, V, S<span style="color:#ff79c6">&gt;&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">where</span>
</span></span><span style="display:flex;"><span>    K: <span style="color:#50fa7b">Borrow</span><span style="color:#ff79c6">&lt;</span>Q<span style="color:#ff79c6">&gt;</span>,
</span></span><span style="display:flex;"><span>    Q: <span style="color:#50fa7b">Hash</span> <span style="color:#ff79c6">+</span> <span style="color:#8be9fd;font-style:italic">Eq</span> <span style="color:#ff79c6">+</span> <span style="color:#ff79c6">?</span><span style="color:#8be9fd;font-style:italic">Sized</span>, { self._get(key) }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">pub</span> <span style="color:#ff79c6">struct</span> <span style="color:#50fa7b">Ref</span><span style="color:#ff79c6">&lt;</span><span style="color:#50fa7b">&#39;a</span>, K, V, S <span style="color:#ff79c6">=</span> RandomState<span style="color:#ff79c6">&gt;</span> {
</span></span><span style="display:flex;"><span>    _guard: <span style="color:#50fa7b">RwLockReadGuard</span><span style="color:#ff79c6">&lt;</span><span style="color:#50fa7b">&#39;a</span>, HashMap<span style="color:#ff79c6">&lt;</span>K, V, S<span style="color:#ff79c6">&gt;&gt;</span>,
</span></span><span style="display:flex;"><span>    k: <span style="color:#ff79c6">*</span><span style="color:#ff79c6">const</span> K,
</span></span><span style="display:flex;"><span>    v: <span style="color:#ff79c6">*</span><span style="color:#ff79c6">const</span> V,
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">pub</span> <span style="color:#ff79c6">type</span> <span style="color:#50fa7b">RwLockReadGuard</span><span style="color:#ff79c6">&lt;</span><span style="color:#50fa7b">&#39;a</span>, T<span style="color:#ff79c6">&gt;</span> <span style="color:#ff79c6">=</span> lock_api::RwLockReadGuard<span style="color:#ff79c6">&lt;</span><span style="color:#50fa7b">&#39;a</span>, RawRwLock, T<span style="color:#ff79c6">&gt;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">//part of lock_api
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span><span style="color:#ff79c6">pub</span> <span style="color:#ff79c6">struct</span> <span style="color:#50fa7b">RwLockReadGuard</span><span style="color:#ff79c6">&lt;</span><span style="color:#50fa7b">&#39;a</span>, R: <span style="color:#50fa7b">RawRwLock</span>, T: <span style="color:#ff79c6">?</span><span style="color:#8be9fd;font-style:italic">Sized</span><span style="color:#ff79c6">&gt;</span> {
</span></span><span style="display:flex;"><span>    rwlock: <span style="color:#ff79c6">&amp;</span><span style="color:#50fa7b">&#39;a</span> <span style="color:#50fa7b">RwLock</span><span style="color:#ff79c6">&lt;</span>R, T<span style="color:#ff79c6">&gt;</span>,
</span></span><span style="display:flex;"><span>    marker: <span style="color:#50fa7b">PhantomData</span><span style="color:#ff79c6">&lt;</span>(<span style="color:#ff79c6">&amp;</span><span style="color:#50fa7b">&#39;a</span> T, R::GuardMarker)<span style="color:#ff79c6">&gt;</span>,
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><ul>
<li>The <code>get</code> method of <code>DashMap</code> returns an <code>Option&lt;Ref&lt;'a, K, V, S&gt;&gt;</code>.</li>
<li><code>Ref</code> is a publicly available struct with a lifetime annotation <code>'a</code>, which is tied to the lifetime of <code>RwLockReadGuard</code>.</li>
<li>The lifetime of <code>RwLockReadGuard</code> of <code>DashMap</code> is tied to the lifetime of <code>lock_api::RwLockReadGuard</code>.</li>
<li>The lifetime of <code>RwLockReadGuard</code> is tied to the lifetime of <code>RwLock</code></li>
</ul>
<p>This means if we decide to return a reference to the value for a key, we are actually returning <code>DashMap's Ref</code> and also <em>holding a lock</em> against the <em>shard</em> that the key belongs to.</p>
<p>The <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/store/mod.rs" target="_blank" rel="noopener">Store</a>
 abstraction in <strong>CacheD</strong> provides <code>get_ref</code> method that returns an instance of <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/store/key_value_ref.rs" target="_blank" rel="noopener">KeyValueRef</a>
 which wraps <code>DashMap's Ref</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#ff79c6">pub</span>(<span style="color:#ff79c6">crate</span>) <span style="color:#ff79c6">fn</span> <span style="color:#50fa7b">get_ref</span>(<span style="color:#ff79c6">&amp;</span>self, key: <span style="color:#ff79c6">&amp;</span><span style="color:#50fa7b">Key</span>) -&gt; <span style="color:#8be9fd;font-style:italic">Option</span><span style="color:#ff79c6">&lt;</span>KeyValueRef<span style="color:#ff79c6">&lt;</span><span style="color:#8be9fd;font-style:italic">&#39;_</span>, Key, StoredValue<span style="color:#ff79c6">&lt;</span>Value<span style="color:#ff79c6">&gt;&gt;&gt;</span> {<span style="color:#ff79c6">..</span>.}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">pub</span> <span style="color:#ff79c6">struct</span> <span style="color:#50fa7b">KeyValueRef</span><span style="color:#ff79c6">&lt;</span><span style="color:#50fa7b">&#39;a</span>, Key, Value<span style="color:#ff79c6">&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">where</span> Key: <span style="color:#8be9fd;font-style:italic">Eq</span> <span style="color:#ff79c6">+</span> Hash {
</span></span><span style="display:flex;"><span>    key_value_ref: <span style="color:#50fa7b">Ref</span><span style="color:#ff79c6">&lt;</span><span style="color:#50fa7b">&#39;a</span>, Key, Value<span style="color:#ff79c6">&gt;</span>,
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>At the same time, <code>Store</code> provides <code>get</code> method if the value is cloneable, which returns an <code>Option&lt;Value&gt;</code>. This behavior will cause <code>DashMap</code> to hold the lock against the shard
while the value is being read, clone the value, return the value to the client, and drop the lock. This is a tradeoff (of sorts) in both the methods: <code>get_ref</code> and <code>get</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#ff79c6">impl</span><span style="color:#ff79c6">&lt;</span>Key, Value<span style="color:#ff79c6">&gt;</span> Store<span style="color:#ff79c6">&lt;</span>Key, Value<span style="color:#ff79c6">&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">where</span> Key: <span style="color:#50fa7b">Hash</span> <span style="color:#ff79c6">+</span> <span style="color:#8be9fd;font-style:italic">Eq</span>,
</span></span><span style="display:flex;"><span>          Value: <span style="color:#8be9fd;font-style:italic">Clone</span>, {
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">pub</span>(<span style="color:#ff79c6">crate</span>) <span style="color:#ff79c6">fn</span> <span style="color:#50fa7b">get</span>(<span style="color:#ff79c6">&amp;</span>self, key: <span style="color:#ff79c6">&amp;</span><span style="color:#50fa7b">Key</span>) -&gt; <span style="color:#8be9fd;font-style:italic">Option</span><span style="color:#ff79c6">&lt;</span>Value<span style="color:#ff79c6">&gt;</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#8be9fd;font-style:italic">let</span> maybe_value <span style="color:#ff79c6">=</span> self.store.get(key);
</span></span><span style="display:flex;"><span>        <span style="color:#8be9fd;font-style:italic">let</span> mapped_value <span style="color:#ff79c6">=</span> maybe_value
</span></span><span style="display:flex;"><span>            .filter(<span style="color:#ff79c6">|</span>stored_value<span style="color:#ff79c6">|</span> stored_value.is_alive(<span style="color:#ff79c6">&amp;</span>self.clock))
</span></span><span style="display:flex;"><span>            .map(<span style="color:#ff79c6">|</span>key_value_ref<span style="color:#ff79c6">|</span> { key_value_ref.value().value() }); <span style="color:#6272a4">//clone the value
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>
</span></span><span style="display:flex;"><span>        mapped_value
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Let&rsquo;s bring another requirement: &ldquo;memory bound cache&rdquo;.</p>
<h3 id="making-the-cache-memory-bound">Making the cache memory bound</h3>
<p>We want to design a cache that uses a fixed amount of memory determined by some configuration parameter.</p>
<p>This requirement brings in two concepts:</p>
<ol>
<li>Every key/value pair should take some size, and we should be able to determine the total size used by the cache.</li>
<li>We must ensure the total cache size does not exceed the specified limit.</li>
</ol>
<blockquote>
<p><strong>CacheD</strong> uses the term &ldquo;weight&rdquo; to denote the space (/size).</p>
</blockquote>
<p>Let&rsquo;s understand the first point.</p>
<p>To associate weight with each key/value pair, we can provide a variant of the <code>put</code> method that takes <code>weight</code> as a parameter along with <code>key</code> and <code>value</code>.
<a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/cached.rs" target="_blank" rel="noopener">Cached</a>
 provides a method <code>put_with_weight()</code> that allows the clients to specify the weight associated with each key/value pair.</p>
<p>Another option is to auto-calculate the weight for each key/value pair. To calculate the weight, we should be able to calculate the size of each key/value pair
using functions like <code>std::mem::size_of_val()</code> or <code>std::mem::size_of()</code> and adding to that the size of any additional metadata, like <code>expiry: Duration</code>, that might be stored
for each key/value pair.</p>
<p>The weight calculation in <strong>CacheD</strong> is available <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/config/weight_calculation.rs" target="_blank" rel="noopener">here</a>
.</p>
<p>Now that we have calculated the weight of each key/value pair, we should maintain the weight of each key and the total weight used by the cache.</p>
<p><strong>CacheD</strong> uses <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/policy/cache_weight.rs" target="_blank" rel="noopener">CacheWeight</a>
 as an abstraction to maintain the weight of each key in the cache, and it also keeps the total weight used by the cache.
The weight of each key is maintained via the <code>WeightedKey</code> abstraction that contains the <code>key</code>, <code>key_hash</code> and its <code>weight</code>.
Every <code>put</code> increases the <em>cache weight</em>, every delete reduces the <em>cache weight</em>, and every update probably changes the <em>cache weight</em>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#ff79c6">pub</span>(<span style="color:#ff79c6">crate</span>) <span style="color:#ff79c6">struct</span> <span style="color:#50fa7b">CacheWeight</span><span style="color:#ff79c6">&lt;</span>Key<span style="color:#ff79c6">&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">where</span> Key: <span style="color:#50fa7b">Hash</span> <span style="color:#ff79c6">+</span> <span style="color:#8be9fd;font-style:italic">Eq</span> <span style="color:#ff79c6">+</span> <span style="color:#8be9fd;font-style:italic">Send</span> <span style="color:#ff79c6">+</span> <span style="color:#8be9fd;font-style:italic">Sync</span> <span style="color:#ff79c6">+</span> <span style="color:#8be9fd;font-style:italic">Clone</span> <span style="color:#ff79c6">+</span> <span style="color:#8be9fd;font-style:italic">&#39;static</span>, {
</span></span><span style="display:flex;"><span>    max_weight: <span style="color:#50fa7b">Weight</span>,
</span></span><span style="display:flex;"><span>    weight_used: <span style="color:#50fa7b">RwLock</span><span style="color:#ff79c6">&lt;</span>Weight<span style="color:#ff79c6">&gt;</span>,
</span></span><span style="display:flex;"><span>    key_weights: <span style="color:#50fa7b">DashMap</span><span style="color:#ff79c6">&lt;</span>KeyId, WeightedKey<span style="color:#ff79c6">&lt;</span>Key<span style="color:#ff79c6">&gt;&gt;</span>,
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We have the weight associated with each key/value pair.</p>
<h3 id="admission-and-eviction-policy">Admission and eviction policy</h3>
<p>Our cache is a memory-bound cache, and this poses an exciting challenge.</p>
<p><em>Should we admit the incoming key/value pair after the cache has reached its weight? If yes, which keys should be evicted to create the space because we can not let
the total cache weight increase beyond some threshold?</em></p>
<p>This is where the paper <a href="https://dgraph.io/blog/refs/TinyLFU%20-%20A%20Highly%20Efficient%20Cache%20Admission%20Policy.pdf" target="_blank" rel="noopener">TinyLFU</a>
 comes into the picture.
The main idea is to only let in a new key/value pair if its access estimate exceeds that of the item being evicted. This means that the incoming
key/value pair should be more valuable to the cache than some existing key/value pairs, improving the hit ratio.</p>
<p>Let&rsquo;s look at the approach:</p>
<p><strong>Approach</strong>:</p>
<ol>
<li>Get an estimate of the access frequency of the incoming key. The incoming key has not been accessed yet, but we <em>might</em> get some access count
because of hash conflicts since we rely on the probabilistic data structure <a href="https://tech-lessons.in/blog/count_min_sketch/" target="_blank" rel="noopener">count-min sketch</a>

to maintain the access frequencies of the keys.</li>
<li>Get a sample of the existing keys (from <code>CacheWeight</code>) that consists of <code>keyId</code>, its <code>weight</code> and <code>its access frequency</code>. <em>Sample size can be configurable.</em></li>
<li>Pick the key with the smallest access frequency from the sample. Let&rsquo;s call this key <em>K1</em>.</li>
<li>If the access frequency of the incoming key is less than the access frequency of the key <em>K1</em>, then reject the incoming key because
its access frequency is less than the smallest access frequency in the sample.</li>
<li>Else, <code>delete</code> the key <em>K1</em> and create the space in the cache. The space created will be equal to the <code>weight of K1</code>.</li>
<li>Repeat the process until either the incoming key is rejected or enough space to accommodate the incoming key is created in the cache.</li>
</ol>
<p>This approach is called &ldquo;Sampled LFU&rdquo;.
<strong>CacheD</strong> uses <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/policy/admission_policy.rs" target="_blank" rel="noopener">AdmissionPolicy</a>
 abstraction to decide whether an incoming key/value pair should be admitted.</p>
<p>There is still one more case to consider. What if there is a key with high access frequency, and it has been a while since it has been seen. Will it never get evicted?</p>
<p>This point is around the recency of key access. The <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/lfu/tiny_lfu.rs" target="_blank" rel="noopener">TinyLFU</a>
 abstraction ensures the recency of key access by the <code>reset</code> method.
We have used <code>count-min sketch</code> to maintain each key&rsquo;s access frequency; every time a key is accessed, the frequency counter is incremented.
After N key increments, the counters get halved. So, a key that has not been seen for a while would also have its counter reset to half of the original value;
thereby providing a chance to the new incoming keys to get in. *<a href="https://dgraph.io/blog/refs/TinyLFU%20-%20A%20Highly%20Efficient%20Cache%20Admission%20Policy.pdf" target="_blank" rel="noopener">TinyLFU paper section: Freshness Mechanism</a>
</p>
<blockquote>
<blockquote>
<p>The abstraction <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/lfu/tiny_lfu.rs" target="_blank" rel="noopener">TinyLFU</a>
 has a <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/lfu/frequency_counter.rs" target="_blank" rel="noopener">FrequencyCounter</a>
 and a <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/lfu/doorkeeper.rs" target="_blank" rel="noopener">DoorKeeper</a>
.
DoorKeeper is implemented using a <a href="https://tech-lessons.in/blog/bloom_filter/" target="_blank" rel="noopener">Bloom filter</a>
. Before increasing the access frequency of a key in <code>FrequencyCounter</code>,
a check is done in the <code>DoorKeeper</code> to see if the key is present. Only if the key is present in the <code>DoorKeeper</code>, its access count is incremented.
This ensures that <code>FrequencyCounter</code> does not have a long tail of keys that are not seen more than once.</p>
</blockquote>
</blockquote>
<p>Our cache is concurrent, so let&rsquo;s understand how to deal with contention.</p>
<h3 id="introducing-bp-wrapper">Introducing BP-Wrapper</h3>
<p>We have already seen <code>Store</code> and <code>count-min sketch</code> based <code>FrequencyCounter</code>. Technically, both are shared data structures prone to <a href="https://stackoverflow.com/questions/1970345/what-is-thread-contention" target="_blank" rel="noopener">contention</a>
.</p>
<p>Let&rsquo;s understand this with an example. Imagine there is a <code>get</code> request for an existing key &ldquo;topic&rdquo;. The key has been accessed, so we should increment the access counter for the key.
<code>FrequencyCounter</code> is a shared data structure, so an option to increment the access counter is to take a lock on the entire data structure and then increment the
count. If multiple threads try to increase the access count for the same or different keys, all these threads would be contending for a single write lock on <code>FrequencyCounter</code>.</p>
<p>This is where the paper <a href="https://dgraph.io/blog/refs/bp_wrapper.pdf" target="_blank" rel="noopener">BP-Wrapper</a>
 comes in. This paper suggests two ways of dealing with contention <em>prefetching</em> and <em>batching</em>.</p>
<p><strong>CacheD</strong> uses <em>batching</em> with <code>get</code> and <code>put</code> operations.</p>
<h4 id="get">Get</h4>
<p>A <code>get</code> operation returns the value for a key if it exists. It queries the <code>Store</code> and gets the value. The next step in <code>get</code> is to increase the access count for the key. This is where
the idea of <em>batching</em> comes in. All the <em>gets</em> are batched in a ring-buffer-like abstraction called <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/pool.rs" target="_blank" rel="noopener">Pool</a>
. <code>Pool</code>
is a collection of <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/pool.rs" target="_blank" rel="noopener">Buffer</a>
 and each <code>Buffer</code> is a collection of hashes of the keys.</p>
<p>Any time a key is accessed, it is added to a buffer within the <code>Pool</code>. When a buffer is full, it is drained. Draining involves sending the entire <code>Vec&lt;KeyHash&gt;</code> to a <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/buffer_event.rs" target="_blank" rel="noopener">BufferConsumer</a>
.
<code>BufferConsumer</code> is implemented using a single thread that receives the buffer content from a <a href="https://crates.io/crates/crossbeam-channel" target="_blank" rel="noopener">channel</a>
. The <code>BufferConsumer</code> on receiving the buffer content applies it to the <code>FrequencyCounter</code>, thereby incrementing the frequency access of the entire set of keys.
The channel size is kept small to reduce contention and the memory footprint of collecting the buffer in memory. If the channel is full, the buffer content is dropped.</p>
<p><a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/policy/admission_policy.rs" target="_blank" rel="noopener">AdmissionPolicy</a>
 plays the role of <code>BufferConsumer</code> in <strong>CacheD</strong>.</p>
<blockquote>
<blockquote>
<p>The current implementation of <strong>CacheD</strong> uses a fine-grained lock over each buffer: <code>buffers: Vec&lt;RwLock&lt;Buffer&lt;Consumer&gt;&gt;&gt;</code>. The next release may change this implementation.</p>
</blockquote>
</blockquote>
<h4 id="put">Put</h4>
<p>The idea with <code>get</code> was to buffer the accesses and apply them to the <code>FrequencyCounter</code> when the buffer gets full. We can not use the same idea with <code>put</code> because we want
to serve the <code>put</code> operations as soon as possible. However, batching is still relevant with <code>put</code> (or any other write) operations.</p>
<p>The idea is to treat every write operation (<code>put</code>, <code>update</code>, <code>delete</code>) as a command, send it to a <a href="https://doc.rust-lang.org/std/sync/mpsc/" target="_blank" rel="noopener">mpsc channel</a>
 and have a single thread receive
commands from the channel and execute them one after the other.</p>
<p><strong>CacheD</strong> follows the same idea. Every write operation goes as a <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/command/mod.rs" target="_blank" rel="noopener">Command</a>
 to the
<a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/command/command_executor.rs" target="_blank" rel="noopener">CommandExecutor</a>
. <code>CommandExecutor</code> is implemented as a single thread
that receives commands from a <a href="https://crates.io/crates/crossbeam-channel" target="_blank" rel="noopener">crossbeam-channel</a>
. Every time a command is received, it is executed by this single thread of execution.</p>
<p>This design choice has obvious implications.</p>
<ul>
<li>There is no guarantee that a <code>put</code> operation will happen successfully because it may be rejected by the <code>AdmissionPolicy</code> as described in the section <a href="#admission-and-eviction-policy">Admission and eviction policy</a>
</li>
<li>All the write operations are processed at a later point in time</li>
</ul>
<p>The solution to both these points lies in providing the right feedback to the clients. <strong>CacheD</strong> provides <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/command/acknowledgement.rs" target="_blank" rel="noopener">CommandAcknowledgementHandle</a>
 as an abstraction that implements the <a href="https://doc.rust-lang.org/std/future/trait.Future.html" target="_blank" rel="noopener">Future</a>
 trait.
Every write operation is returned an instance of <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/command/command_executor.rs" target="_blank" rel="noopener">CommandSendResult</a>
 that wraps
<code>CommandAcknowledgement</code>, which provides a <code>handle()</code> method to return a <code>CommandAcknowledgementHandle</code> to the clients.</p>
<p>Clients can perform <code>await</code> on the <code>CommandAcknowledgementHandle</code> and get the <a href="https://github.com/SarthakMakhija/cached/blob/main/src/cache/command/mod.rs" target="_blank" rel="noopener">CommandStatus</a>
.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#ff79c6">#[tokio::main]</span>
</span></span><span style="display:flex;"><span> <span style="color:#ff79c6">async</span> <span style="color:#ff79c6">fn</span> <span style="color:#50fa7b">main</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd;font-style:italic">let</span> cached <span style="color:#ff79c6">=</span> CacheD::new(ConfigBuilder::new(<span style="color:#bd93f9">100</span>, <span style="color:#bd93f9">10</span>, <span style="color:#bd93f9">100</span>).build());
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd;font-style:italic">let</span> status <span style="color:#ff79c6">=</span> cached.put(<span style="color:#f1fa8c">&#34;topic&#34;</span>, <span style="color:#f1fa8c">&#34;microservices&#34;</span>).unwrap().handle().<span style="color:#ff79c6">await</span>;
</span></span><span style="display:flex;"><span>    assert_eq!(CommandStatus::Accepted, status);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We have most of the building blocks for our cache; let&rsquo;s now jump to the metrics collection in the cache.</p>
<h3 id="measuring-metrics">Measuring metrics</h3>
<p>At the end of the day, we would like to know how our cache is behaving. We want to collect counter-based metrics like <em>CacheHits</em>, <em>CacheMisses</em>, <em>KeysAdded</em>, <em>KeysDeleted</em> etc.</p>
<p>Let&rsquo;s assume there are 16 such metrics that we want to collect. To do that, we can design a simple <code>ConcurrentStatsCounter</code> that can maintain an array of 16 entries, and
each array element is of type <code>AtomicU64</code>. Whenever an event happens, like a key getting added to the cache, we increment its corresponding counter.<br>
This approach can be represented with the following code:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#ff79c6">const</span> TOTAL_STATS: <span style="color:#8be9fd">usize</span> <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">16</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">#[repr(usize)]</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">#[non_exhaustive]</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">#[derive(Copy, Clone, Eq, PartialEq, Hash, Debug)]</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">pub</span> <span style="color:#ff79c6">enum</span> <span style="color:#50fa7b">StatsType</span> {
</span></span><span style="display:flex;"><span>   KeysAdded <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">0</span>,
</span></span><span style="display:flex;"><span>   KeysDeleted <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">1</span>,
</span></span><span style="display:flex;"><span>   <span style="color:#6272a4">//+ others
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">pub</span>(<span style="color:#ff79c6">crate</span>) <span style="color:#ff79c6">struct</span> <span style="color:#50fa7b">ConcurrentStatsCounter</span> {
</span></span><span style="display:flex;"><span>   entries: [AtomicU64; TOTAL_STATS],
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">pub</span>(<span style="color:#ff79c6">crate</span>) <span style="color:#ff79c6">fn</span> <span style="color:#50fa7b">add_key</span>(<span style="color:#ff79c6">&amp;</span>self) { self.add(StatsType::KeysAdded, <span style="color:#bd93f9">1</span>); }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">fn</span> <span style="color:#50fa7b">add</span>(<span style="color:#ff79c6">&amp;</span>self, stats_type: <span style="color:#50fa7b">StatsType</span>, count: <span style="color:#8be9fd">u64</span>) {
</span></span><span style="display:flex;"><span>   self.entries[stats_type <span style="color:#ff79c6">as</span> <span style="color:#8be9fd">usize</span>].fetch_add(count, Ordering::AcqRel);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The approach looks excellent. However, we need to understand the concept of <code>false sharing</code> before concluding on the approach&rsquo;s greatness.</p>
<h4 id="false-sharing">False sharing</h4>
<p>The memory in the <em>L1</em>, <em>L2</em>, <em>L3</em> and <em>L4</em> processor cache is organized in units called &ldquo;cache lines&rdquo;.
The cache line is the smallest data transfer unit between the main memory and the processor cache. If the cache line size is 64 bytes, then a contiguous block
of 64 bytes will be transferred from RAM to the processor cache for processing. The size of cache lines varies based on the type of the processor.
For example, on <em>x86-64</em>, <em>aarch64</em>, and <em>powerpc64</em>, <a href="https://docs.rs/crossbeam/0.8.2/crossbeam/utils/struct.CachePadded.html" target="_blank" rel="noopener">cache line is 128 bytes</a>
.</p>
<blockquote>
<p>Updating an atomic value invalidates the whole cache line it belongs to.</p>
</blockquote>
<p>Let&rsquo;s go back to our code now. Let&rsquo;s assume that the cache line size is 64 bytes. We have an array of <code>AtomicU64</code>; each <code>AtomicU64</code> takes <em>8 bytes</em> of memory. Our
cache line size is <em>64 bytes</em>, that means eight <code>AtomicU64</code> values will lie in one cache line.</p>
<p>Let&rsquo;s imagine that <em>thread1</em> running on core-1 will update the atomic value at <em>index 0</em> and <em>thread2</em> running on core-2 will update the atomic value at <em>index 1</em>.
We know that these atomic values lie on the same cache line, and &ldquo;updating an atomic value invalidates the whole cache line it belongs to&rdquo;. Invalidating a cache line
will result in fetching that chunk of memory from RAM again.</p>
<p>Consider that <em>thread1</em> running on core-1 updates the atomic value at <em>index 0</em>, invalidating the entire cache line that this value belongs to. Now, <em>thread2</em>
running on core-2 needs to update the value at <em>index 1</em>, but the entire cache line is invalidated. So, the cache line (64 bytes) needs to be fetched from RAM.
Reading/Writing from/to RAM is in the order of <a href="https://kt.academy/article/pmem-intro" target="_blank" rel="noopener">80-100 ns</a>
 compared to the same from <em>L1</em>, <em>L2</em>, <em>L3</em> and <em>L4</em> cache, which is in the order of 1-10 ns.</p>
<p><em>thread2</em> running on core-2 updates the atomic value at <em>index 1</em> after the cache line is fetched. This update invalidates the entire cache line again and forces another
fetch of the cache line from RAM. This fetch/re-fetch/re-re-fetch of the cache line is courtesy of &ldquo;false sharing&rdquo;.</p>
<blockquote>
<p>We are using &ldquo;atomics&rdquo; to ensure that each thread updates its value atomically, and because these values are on the
same cache line, both the threads running on different cores end up <strong>sharing</strong> the same cache line for <strong>writing</strong>. This increases latency
because of the repeated fetch of the cache line(s) from RAM. This is called &ldquo;false sharing&rdquo;. Imagine the extent of the problem with 128 cores.</p>
</blockquote>
<p>The way to deal with &ldquo;false sharing&rdquo; is to pad the values so that each <code>AtomicU64</code> lies on its cache line. One option is to pad the values manually, and the other
is to use a library that can help with padding. <strong>CacheD</strong> uses <a href="https://docs.rs/crossbeam/0.8.2/crossbeam/utils/struct.CachePadded.html" target="_blank" rel="noopener">CachePadded</a>
 to pad the values.</p>
<p>With the introduction of <code>CachePadded</code>, this is how the code looks like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#ff79c6">const</span> TOTAL_STATS: <span style="color:#8be9fd">usize</span> <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">16</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">#[repr(usize)]</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">#[non_exhaustive]</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">#[derive(Copy, Clone, Eq, PartialEq, Hash, Debug)]</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">pub</span> <span style="color:#ff79c6">enum</span> <span style="color:#50fa7b">StatsType</span> {
</span></span><span style="display:flex;"><span>   KeysAdded <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">0</span>,
</span></span><span style="display:flex;"><span>   KeysDeleted <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">1</span>,
</span></span><span style="display:flex;"><span>   <span style="color:#6272a4">//+ others
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">#[repr(transparent)]</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">#[derive(Debug)]</span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">//introduce a new abstraction that wraps AtomicU64 inside CachePadded
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span><span style="color:#ff79c6">struct</span> <span style="color:#50fa7b">Counter</span>(CachePadded<span style="color:#ff79c6">&lt;</span>AtomicU64<span style="color:#ff79c6">&gt;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">//entries now contains Counters instead of AtomicU64
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4">//each Counter is a CachePadded AtomicU64
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4">//therefore, each AtomicU64 is now placed on its own cache line
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span><span style="color:#ff79c6">pub</span>(<span style="color:#ff79c6">crate</span>) <span style="color:#ff79c6">struct</span> <span style="color:#50fa7b">ConcurrentStatsCounter</span> {
</span></span><span style="display:flex;"><span>   entries: [Counter; TOTAL_STATS],   
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">pub</span>(<span style="color:#ff79c6">crate</span>) <span style="color:#ff79c6">fn</span> <span style="color:#50fa7b">add_key</span>(<span style="color:#ff79c6">&amp;</span>self) { self.add(StatsType::KeysAdded, <span style="color:#bd93f9">1</span>); }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">fn</span> <span style="color:#50fa7b">add</span>(<span style="color:#ff79c6">&amp;</span>self, stats_type: <span style="color:#50fa7b">StatsType</span>, count: <span style="color:#8be9fd">u64</span>) {
</span></span><span style="display:flex;"><span>   <span style="color:#6272a4">//fetch_add is now available in Counter
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>   self.entries[stats_type <span style="color:#ff79c6">as</span> <span style="color:#8be9fd">usize</span>].<span style="color:#bd93f9">0.</span>fetch_add(count, Ordering::AcqRel); 
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We are done with all the building blocks :). Great job. Let&rsquo;s understand a way to measure the cache-hit ratio.</p>
<h3 id="measuring-cache-hit-ratio">Measuring cache-hit ratio</h3>
<p>Hit ratio is defined by the following formula:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span>Hit ratio <span style="color:#ff79c6">=</span> number of hits<span style="color:#ff79c6">/</span>(number of hits <span style="color:#ff79c6">+</span> number of misses) 
</span></span><span style="display:flex;"><span>or 
</span></span><span style="display:flex;"><span>Hit ratio <span style="color:#ff79c6">as</span> percentage <span style="color:#ff79c6">=</span> (number of hits<span style="color:#ff79c6">/</span>(number of hits <span style="color:#ff79c6">+</span> number of misses)) <span style="color:#ff79c6">*</span> <span style="color:#bd93f9">100</span>
</span></span></code></pre></div><p>Let&rsquo;s understand the problem better. We need the following:</p>
<ol>
<li>A distribution of elements of type <code>T</code>. We will be performing <code>get</code> and <code>put</code> operations using the elements of this distribution. The distribution:
<ul>
<li>should consist of values (/elements) within the specified range</li>
<li>should have some way of defining the repetition of elements (some elements should occur M times, some should occur P times, while some should occur just one time)</li>
</ul>
</li>
<li>For each element, perform a <code>get</code> operation in the cache
<ul>
<li>This results in measuring the hits and misses</li>
</ul>
</li>
<li>If the element is not present, perform a <code>put</code> operation in the cache
<ul>
<li>This results in adding a new element from the distribution in the cache</li>
</ul>
</li>
</ol>
<h4 id="distribution-of-elements">Distribution of elements</h4>
<p>The distribution of elements is a collection of N elements of type <code>T</code> that will be loaded in the cache via <code>put</code> operation and the elements from this distribution
will be queried from the cache via <code>get</code> operation. This distribution should be able to repeat elements based on some logic.</p>
<p>Let&rsquo;s take a look at <a href="https://en.wikipedia.org/wiki/Zipf%27s_law" target="_blank" rel="noopener">Zipf's law</a>
.</p>
<blockquote>
<blockquote>
<p>Zipf&rsquo;s law often holds, approximately, when a list of measured values is sorted in decreasing order. It states that the value of the nth entry is inversely proportional to n.
The best known instance of Zipf&rsquo;s law applies to the frequency table of words in a text or corpus of natural language.
Namely, it is usually found that the most common word occurs approximately twice as often as the next common one, three times as often as the third most common, and so on. For example, in the Brown Corpus of American English text, the word &ldquo;the&rdquo; is the most frequently occurring word, and by itself accounts for nearly 7% of all word occurrences (69,971 out of slightly over 1 million). True to Zipf&rsquo;s Law, the second-place word &ldquo;of&rdquo; accounts for slightly over 3.5% of words (36,411 occurrences), followed by &ldquo;and&rdquo; (28,852).
(<a href="https://en.wikipedia.org/wiki/Zipf%27s_law" target="_blank" rel="noopener">Referenced from</a>
).</p>
</blockquote>
</blockquote>
<p>If the words are ranked according to their frequencies in a large collection, then the frequency will decline as the rank increases, so a small number of items appear very often, and a large number rarely occur. (<a href="https://www.techtarget.com/whatis/definition/Zipfs-Law" target="_blank" rel="noopener">Reference</a>
).</p>
<p>This idea matches what we want. We can use the Zipf distribution to check cache hits because it will cause some elements to appear frequently while others will appear rarely. In the rust ecosystem, the crate <a href="https://docs.rs/rand_distr/0.4.3/rand_distr/struct.Zipf.html" target="_blank" rel="noopener">rand_distr</a>

provides the Zipf distribution.</p>
<p>We have the distribution part sorted out. Now, we can write a benchmark that loads K elements of the distribution in a cache with weight W. All we need to do is identify K and W.</p>
<p>The idea is to have a large enough distribution sample, and <strong>CacheD</strong> uses a distribution size of <em>16 * 100_000</em>, which means the Zipf distribution will contain <em>16 * 100_000</em>
elements with the biggest value as <em>16 * 100_000</em>. So, our K = <em>16 * 100_000</em>.</p>
<p>Each key/value pair that is being loaded is of type <code>u64</code>, and the weight of a single key/value pair is <em>40 bytes</em>.</p>
<p>We want the cache weight to be less than the total weight of the incoming elements to simulate <a href="#admission-and-eviction-policy">rejections</a>
. We keep the cache weight to be <em>1/16</em>th of the total weight of the incoming elements.
That means the cache weight (W) = <em>100_000 * 40 bytes</em>. That&rsquo;s it; we are now ready to run the <a href="https://github.com/SarthakMakhija/cached/blob/main/benches/benchmarks/cache_hits.rs" target="_blank" rel="noopener">benchmark</a>
.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#f1fa8c">/// Defines the total number of key/value pairs that may be loaded in the cache
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c"></span><span style="color:#ff79c6">const</span> CAPACITY: <span style="color:#8be9fd">usize</span> <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">100_000</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f1fa8c">/// Defines the total number of counters used to measure the access frequency.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c"></span><span style="color:#ff79c6">const</span> COUNTERS: <span style="color:#50fa7b">TotalCounters</span> <span style="color:#ff79c6">=</span> (CAPACITY <span style="color:#ff79c6">*</span> <span style="color:#bd93f9">10</span>) <span style="color:#ff79c6">as</span> TotalCounters;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f1fa8c">/// Defines the total size of the cache.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">/// It is kept to CAPACITY * 40 because the benchmark inserts keys and values with weight 40.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c"></span><span style="color:#ff79c6">const</span> WEIGHT: <span style="color:#50fa7b">Weight</span> <span style="color:#ff79c6">=</span> (CAPACITY <span style="color:#ff79c6">*</span> <span style="color:#bd93f9">40</span>) <span style="color:#ff79c6">as</span> Weight;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f1fa8c">/// Defines the total sample size that is used for generating Zipf distribution.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">/// Here, ITEMS is 16 times the CAPACITY to provide a larger sample for Zipf distribution.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">/// W/C = 16, W denotes the sample size, and C is the cache size
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c"></span><span style="color:#ff79c6">const</span> ITEMS: <span style="color:#8be9fd">usize</span> <span style="color:#ff79c6">=</span> CAPACITY <span style="color:#ff79c6">*</span> <span style="color:#bd93f9">16</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">pub</span> <span style="color:#ff79c6">fn</span> <span style="color:#50fa7b">cache_hits_single_threaded_exponent_1_001</span>(criterion: <span style="color:#ff79c6">&amp;</span><span style="color:#50fa7b">mut</span> Criterion) {
</span></span><span style="display:flex;"><span>   criterion.bench_function(<span style="color:#f1fa8c">&#34;Cached.get()&#34;</span>, <span style="color:#ff79c6">|</span>bencher<span style="color:#ff79c6">|</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#8be9fd;font-style:italic">let</span> runtime <span style="color:#ff79c6">=</span> Builder::new_multi_thread()
</span></span><span style="display:flex;"><span>              .worker_threads(<span style="color:#bd93f9">1</span>)
</span></span><span style="display:flex;"><span>              .enable_all()
</span></span><span style="display:flex;"><span>              .build()
</span></span><span style="display:flex;"><span>              .unwrap();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      bencher.to_async(runtime).iter_custom(<span style="color:#ff79c6">|</span>iterations<span style="color:#ff79c6">|</span> {
</span></span><span style="display:flex;"><span>         <span style="color:#ff79c6">async</span> <span style="color:#ff79c6">move</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#8be9fd;font-style:italic">let</span> cached <span style="color:#ff79c6">=</span> CacheD::new(ConfigBuilder::new(COUNTERS, CAPACITY, WEIGHT).build());
</span></span><span style="display:flex;"><span>            <span style="color:#8be9fd;font-style:italic">let</span> distribution <span style="color:#ff79c6">=</span> distribution_with_exponent(ITEMS <span style="color:#ff79c6">as</span> <span style="color:#8be9fd">u64</span>, ITEMS, <span style="color:#bd93f9">1.001</span>); <span style="color:#6272a4">//Zipf exponent
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>
</span></span><span style="display:flex;"><span>            <span style="color:#8be9fd;font-style:italic">let</span> hit_miss_recorder <span style="color:#ff79c6">=</span> HitsMissRecorder::new();
</span></span><span style="display:flex;"><span>            <span style="color:#8be9fd;font-style:italic">let</span> <span style="color:#ff79c6">mut</span> index <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">0</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#8be9fd;font-style:italic">let</span> start <span style="color:#ff79c6">=</span> Instant::now();
</span></span><span style="display:flex;"><span>            <span style="color:#ff79c6">for</span> _ <span style="color:#ff79c6">in</span> <span style="color:#bd93f9">0</span><span style="color:#ff79c6">..</span>CAPACITY<span style="color:#ff79c6">*</span><span style="color:#bd93f9">16</span> {
</span></span><span style="display:flex;"><span>               <span style="color:#8be9fd;font-style:italic">let</span> option <span style="color:#ff79c6">=</span> cached.get(<span style="color:#ff79c6">&amp;</span>distribution[index]);
</span></span><span style="display:flex;"><span>               <span style="color:#ff79c6">if</span> option.is_some() {
</span></span><span style="display:flex;"><span>                  hit_miss_recorder.record_hit();
</span></span><span style="display:flex;"><span>               } <span style="color:#ff79c6">else</span> {
</span></span><span style="display:flex;"><span>                  hit_miss_recorder.record_miss();
</span></span><span style="display:flex;"><span>               }
</span></span><span style="display:flex;"><span>               cached.put_with_weight(distribution[index], distribution[index], <span style="color:#bd93f9">40</span>).unwrap().handle().<span style="color:#ff79c6">await</span>;
</span></span><span style="display:flex;"><span>               index <span style="color:#ff79c6">+=</span> <span style="color:#bd93f9">1</span>;
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>            cached.shutdown();
</span></span><span style="display:flex;"><span>            println!(<span style="color:#f1fa8c">&#34;</span><span style="color:#f1fa8c">{:?}</span><span style="color:#f1fa8c"> %&#34;</span>, hit_miss_recorder.ratio());
</span></span><span style="display:flex;"><span>            start.elapsed()
</span></span><span style="display:flex;"><span>         }
</span></span><span style="display:flex;"><span>      });
</span></span><span style="display:flex;"><span>   });
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The result for cache-hits in <strong>CacheD</strong> is available <a href="https://github.com/SarthakMakhija/cached#measuring-cache-hit-ratio" target="_blank" rel="noopener">here</a>
.</p>
<p>That&rsquo;s it. We have all the building blocks needed to build an in-memory LFU cache.</p>
<h3 id="code">Code</h3>
<p>The source code of <strong>CacheD</strong> is available <a href="https://github.com/SarthakMakhija/cached" target="_blank" rel="noopener">here</a>
 and the crate is available <a href="https://crates.io/crates/tinylfu-cached" target="_blank" rel="noopener">here</a>
.</p>
<h3 id="relevant-research-papers">Relevant research papers</h3>
<ul>
<li><a href="https://dgraph.io/blog/refs/TinyLFU%20-%20A%20Highly%20Efficient%20Cache%20Admission%20Policy.pdf" target="_blank" rel="noopener">TinyLFU</a>
</li>
<li><a href="https://dgraph.io/blog/refs/bp_wrapper.pdf" target="_blank" rel="noopener">BP-Wrapper</a>
</li>
</ul>
<h3 id="references">References</h3>
<ul>
<li><a href="https://dgraph.io/blog/post/introducing-ristretto-high-perf-go-cache/" target="_blank" rel="noopener">Ristretto</a>
</li>
<li><a href="https://en.wikipedia.org/wiki/Zipf%27s_law" target="_blank" rel="noopener">Zipf's law wikipedia</a>
</li>
<li><a href="https://www.techtarget.com/whatis/definition/Zipfs-Law" target="_blank" rel="noopener">Zipf's law techtarget</a>
</li>
</ul>

  </article>
<div class="tag-list-container">
    <div class="tag-list">
        
        <a class="button" href="">
            <p class="tag"><i class="fa fa-fw fa-tag"></i>Cache</p>
        </a>
        
        <a class="button" href="">
            <p class="tag"><i class="fa fa-fw fa-tag"></i>TinyLFU</p>
        </a>
        
        <a class="button" href="">
            <p class="tag"><i class="fa fa-fw fa-tag"></i>CacheD</p>
        </a>
        
    </div>
</div>



<div class="px-2 mb-2">
  
  <script src="https://giscus.app/client.js"
    data-repo="SarthakMakhija/tech-lessons-comments"
    data-repo-id="R_kgDOJHu3mA"
    data-category="Announcements"
    data-category-id="DIC_kwDOJHu3mM4CUxhS"
    data-mapping="og:title"
    data-strict="0"
    data-reactions-enabled="1"
    data-emit-metadata="0"
    data-input-position="bottom"
    data-theme="light"
    data-lang="en"
    crossorigin="anonymous"
    async>
  </script>
  
</div>



    </main><footer class="container p-6 mx-auto flex justify-between items-center">
  <span></span>

  <span class="text-base font-thin">
    
    tech-lessons.in Â© 2020 / Powered by  <a class="font-bold" target="_blank" href="https://gohugo.io/">Hugo</a>
    
  </span>

  <span onclick="window.scrollTo({top: 0, behavior: 'smooth'})" class="p-1 cursor-pointer">
    <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5"
      stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M18 15l-6 -6l-6 6h12" />
    </svg>
  </span>
</footer>

<div class="search-ui absolute top-0 left-0 w-full h-full bg-white dark:bg-gray-800 hidden">
  <div class="container max-w-3xl mx-auto p-12">
    <div class="relative">
      <div class="my-4 text-center text-2xl font-bold">Search</div>

      <span class="p-2 absolute right-0 top-0 cursor-pointer close-search">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5"
          stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <line x1="18" y1="6" x2="6" y2="18" />
          <line x1="6" y1="6" x2="18" y2="18" />
        </svg>
      </span>
    </div>

    <input type="search" class="py-2 px-3 w-full dark:text-black border dark:border-transparent"
      placeholder="Enter search query" />

    <div class="search-results text-lg font-medium my-4 hidden">Results</div>
    <ul class="search-list my-2">

    </ul>

    <div class="no-results text-center my-8 hidden">
      <div class="text-xl font-semibold mb-2">No results found</div>
      <p class="font-light text-sm">Try adjusting your search query</p>
    </div>
  </div>
</div>





<script src="//localhost:1313/js/scripts.min.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-9KKTKFQ2CM"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-9KKTKFQ2CM');
        }
      </script>





<script>
  const mobileMenuButton = document.querySelector('.mobile-menu-button')
  const mobileMenu = document.querySelector('.mobile-menu')
  function toggleMenu() {
    mobileMenu.classList.toggle('hidden');
    mobileMenu.classList.toggle('flex');
  }
  if(mobileMenu && mobileMenuButton){
    mobileMenuButton.addEventListener('click', toggleMenu)
  }
</script>
</body>
</html>
