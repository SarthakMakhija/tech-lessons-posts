<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <link rel="icon" href="/favicon.png">

  <title>
  WiscKey: Separating Keys from Values in SSD-Conscious Storage - tech-lessons.in
  </title>
  <meta name="description" content="LSM-tree (Log structured merge tree) is a data structure typically used when dealing with write-heavy workloads. LSM-tree optimizes the write-path by performing sequential writes to disk. WiscKey is a persistent LSM-tree-based key-value store that separates keys from values to minimize read and write amplification. The design of WiscKey is highly SSD optimized, leveraging both the sequential and random performance characteristics of the device." />
  <meta name="author" content="Sarthak Makhija" />
  
     <meta property="og:image" content="/wisckey.webp" />
  <meta name="generator" content="Hugo 0.140.1"><link rel="stylesheet" href="/css/styles.css" />

  
  

  <meta property="og:url" content="//localhost:1313/en/blog/wisckey_ssd_conscious_key_value_store/">
  <meta property="og:site_name" content="tech-lessons.in">
  <meta property="og:title" content="WiscKey: Separating Keys from Values in SSD-Conscious Storage">
  <meta property="og:description" content="LSM-tree (Log structured merge tree) is a data structure typically used when dealing with write-heavy workloads. LSM-tree optimizes the write-path by performing sequential writes to disk. WiscKey is a persistent LSM-tree-based key-value store that separates keys from values to minimize read and write amplification. The design of WiscKey is highly SSD optimized, leveraging both the sequential and random performance characteristics of the device.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2023-03-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2023-03-10T00:00:00+00:00">
    <meta property="article:tag" content="Storage Engine">
    <meta property="article:tag" content="LSM-Tree">
    <meta property="article:tag" content="WiscKey">
    <meta property="article:tag" content="SSD-Conscious">
    <meta property="article:tag" content="BadgerDb">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="WiscKey: Separating Keys from Values in SSD-Conscious Storage">
  <meta name="twitter:description" content="LSM-tree (Log structured merge tree) is a data structure typically used when dealing with write-heavy workloads. LSM-tree optimizes the write-path by performing sequential writes to disk. WiscKey is a persistent LSM-tree-based key-value store that separates keys from values to minimize read and write amplification. The design of WiscKey is highly SSD optimized, leveraging both the sequential and random performance characteristics of the device.">

  
  <meta itemprop="name" content="WiscKey: Separating Keys from Values in SSD-Conscious Storage">
  <meta itemprop="description" content="LSM-tree (Log structured merge tree) is a data structure typically used when dealing with write-heavy workloads. LSM-tree optimizes the write-path by performing sequential writes to disk. WiscKey is a persistent LSM-tree-based key-value store that separates keys from values to minimize read and write amplification. The design of WiscKey is highly SSD optimized, leveraging both the sequential and random performance characteristics of the device.">
  <meta itemprop="datePublished" content="2023-03-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2023-03-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="5728">
  <meta itemprop="keywords" content="Storage Engine,LSM-Tree,WiscKey,SSD-Conscious,BadgerDb">

  
</head>
<body class="dark:bg-gray-800 dark:text-white relative flex flex-col min-h-screen"><header class="container flex justify-between md:justify-between gap-4 flex-wrap p-6 mx-auto relative">
  <a href="//localhost:1313/en/" class="capitalize font-extrabold text-2xl">
    
    <img src="/logo.png" alt="tech-lessons.in" class="h-8 max-w-full" />
    
  </a>
  <button class="mobile-menu-button md:hidden">
    <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <line x1="4" y1="8" x2="20" y2="8" />
      <line x1="4" y1="16" x2="20" y2="16" />
    </svg>
  </button>
  <ul class="mobile-menu absolute z-10 px-6 pb-6 md:p-0 top-full left-0 w-full md:w-auto md:relative hidden md:flex flex-col md:flex-row items-end md:items-center gap-4 lg:gap-6 bg-white dark:bg-gray-800">

    
    <li><a href="/en/">Home</a></li>
    
    <li><a href="/en/blog">Blogs</a></li>
    
    <li><a href="/en/page/about/">About Me</a></li>
    
    <li><a href="/en/page/projects/">My projects</a></li>
    

    

    
    <li class="grid place-items-center">
      <span class="open-search inline-block cursor-pointer">
        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" stroke-width="1.5"
          stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <circle cx="10" cy="10" r="7" />
          <line x1="21" y1="21" x2="15" y2="15" />
        </svg>
      </span>
    </li>
    

    
  </ul>
</header>
<main class="flex-1">
  
  

  
  <div class="relative max-w-5xl mx-auto px-4">
    <img src="/wisckey.webp" class="rounded-lg shadow-sm w-full object-contain" />
    
    <figcaption class="font-extralight text-xs"><i>Background by Alex Conchillos on Pexels</i></figcaption>
    
    
    <div class="absolute top-4 right-8 rounded shadow bg-white text-gray-900 dark:bg-gray-900 dark:text-white px-2 py-0.5">
      
  
    March 10, 2023
  


    </div>
    
  </div>
  

  <article class="prose lg:prose-lg mx-auto my-8 dark:prose-dark px-4 max-w-5xl">

    <h1 class="text-2xl font-bold mb-2">WiscKey: Separating Keys from Values in SSD-Conscious Storage</h1>
    
    <h5 class="text-sm flex items-center flex-wrap">
      <svg xmlns="http://www.w3.org/2000/svg" class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <rect x="4" y="5" width="16" height="16" rx="2" />
        <line x1="16" y1="3" x2="16" y2="7" />
        <line x1="8" y1="3" x2="8" y2="7" />
        <line x1="4" y1="11" x2="20" y2="11" />
        <rect x="8" y="15" width="2" height="2" />
      </svg>
      Posted on 
  
    March 10, 2023
  


      
        &nbsp;&bull;&nbsp;
      
      <svg xmlns="http://www.w3.org/2000/svg" class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <circle cx="12" cy="12" r="9" />
        <polyline points="12 7 12 12 15 15" />
      </svg>
      27&nbsp;minutes
      &nbsp;&bull;
      <svg xmlns="http://www.w3.org/2000/svg" class="mx-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <path d="M3 19a9 9 0 0 1 9 0a9 9 0 0 1 9 0" />
        <path d="M3 6a9 9 0 0 1 9 0a9 9 0 0 1 9 0" />
        <line x1="3" y1="6" x2="3" y2="19" />
        <line x1="12" y1="6" x2="12" y2="19" />
        <line x1="21" y1="6" x2="21" y2="19" />
      </svg>
      5728&nbsp;words
      
    </h5>
    

    <details id="TableOfContents" class="px-4 mt-4 bg-gray-100 dark:bg-gray-700 rounded toc">
    <summary class="flex items-center font-bold py-2 px-4 cursor-pointer justify-between select-none text-black dark:text-white">
      <span>Table of contents</span>
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-down" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
        <polyline points="6 9 12 15 18 9"></polyline>
     </svg>
    </summary>

    <ul class="mt-2 pb-4">
        

        
        <li>
        <a href="#lsm-tree">LSM-tree</a>
        

        
        </li><li>
        <a href="#leveldb">LevelDB</a>
        

        
        <ul>
            <li>
        <a href="#compaction">Compaction</a>
        

        
        </li></ul>
      </li><li>
        <a href="#read-write-amplification">Read Write amplification</a>
        

        
        </li><li>
        <a href="#analysis-of-read-write-amplification-in-leveldb">Analysis of Read Write amplification in LevelDB</a>
        

        
        <ul>
            <li>
        <a href="#why-does-leveldb-check-only-one-sstable-file-at-each-level-from-level1-to-level6-for-a-read-operation">Why does LevelDB check only one SSTable file at each level from Level1 to Level6, for a read operation?</a>
        

        
        </li><li>
        <a href="#why-is-the-size-of-the-index-section-16kb">Why is the size of the index section 16KB?</a>
        

        
        </li><li>
        <a href="#why-is-the-size-of-the-data-section-just-4kb">Why is the size of the data section just 4KB?</a>
        

        
        </li><li>
        <a href="#why-do-we-need-an-index-block-in-an-sstable-file">Why do we need an index block in an SSTable file?</a>
        

        
        </li></ul>
      </li><li>
        <a href="#ssd-considerations-when-designing-a-storage-engine">SSD considerations when designing a storage engine</a>
        

        
        </li><li>
        <a href="#wisckey-proposal">WiscKey proposal</a>
        

        
        <ul>
            <li>
        <a href="#separate-values-from-keys">Separate values from keys</a>
        

        
        </li><li>
        <a href="#leverage-the-internal-parallelism-of-ssds">Leverage the internal parallelism of SSDs</a>
        

        
        </li><li>
        <a href="#introduce-garbage-collection">Introduce garbage collection</a>
        

        
        </li></ul>
      </li><li>
        <a href="#optimizations-offered-by-wisckey">Optimizations offered by WiscKey</a>
        

        
        <ul>
            <li>
        <a href="#value-log-write-buffer">Value-Log Write Buffer</a>
        

        
        </li><li>
        <a href="#removal-of-lsm-tree-log">Removal of LSM-tree Log</a>
        

        
        </li></ul>
      </li><li>
        <a href="#reference-implementation-of-wisckey">Reference implementation of WiscKey</a>
        

        
        </li><li>
        <a href="#conclusion">Conclusion</a>
        

        
        </li><li>
        <a href="#mention">Mention</a>
        

        
        </li><li>
        <a href="#references">References</a>
        </li></ul>
  </details>

    <blockquote>
<p><a href="https://en.wikipedia.org/wiki/Log-structured_merge-tree#:~:text=In%20computer%20science%2C%20the%20log,%2C%20maintain%20key%2Dvalue%20pairs." target="_blank" rel="noopener">LSM-tree</a>
 (Log structured merge tree) is a data structure typically used for write-heavy workloads. LSM-tree optimizes the write path by performing sequential writes to disk. WiscKey is a persistent LSM-tree-based key-value store that separates keys from values to minimize read and write amplification. The design of WiscKey is highly SSD optimized, leveraging both the device&rsquo;s sequential and random performance characteristics.</p>
</blockquote>
<p>This article summarises the <a href="https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf" target="_blank" rel="noopener">WiscKey</a>
 paper published in 2016.</p>
<p>Before we understand the paper, it is essential to understand the LSM-tree data structure, read and write amplification in the LSM-tree and various SSD characteristics that should be considered while building an SSD-conscious storage engine.</p>
<h3 id="lsm-tree">LSM-tree</h3>
<p>LSM-tree is a write-optimized data structure implemented by storage engines for supporting write-heavy workloads. A lot of storage engines including <a href="https://github.com/dgraph-io/badger" target="_blank" rel="noopener">BadgerDB</a>
, <a href="https://github.com/facebook/rocksdb" target="_blank" rel="noopener">RocksDB</a>
 and
<a href="https://github.com/google/leveldb" target="_blank" rel="noopener">LevelDB</a>
 use LSM-tree as the core data structure.</p>
<blockquote>
<p>Storage engine is a software module that provides data structures for efficient reads and writes. The two most common data structures are B+Tree (read-optimized) and LSM-tree (write-optimized).</p>
</blockquote>
<p>Let&rsquo;s look at the structure of LSM-tree to understand why it is write-optimized.</p>
<p>LSM-tree buffers the data in memory and performs a sequential write to disk after the in-memory buffer is full. The image below highlights the throughput difference between sequential and random writes on an NVMe SSD; the difference would be much higher on an HDD.</p>
<figure>
    <img class="align-center" src="/sequential-random-write.png" /> 
    <figcaption class="figcaption">Sequential write throughput > Random write throughput</figcaption>
</figure>
<blockquote>
<p>LSM-tree-based storage engines offer better write throughput by performing sequential writes to disk.</p>
</blockquote>
<p>LSM-tree consists of components of exponentially increasing sizes, C0 to Ck. C0 is a <em>RAM resident</em> component that stores key-value pairs sorted by key and supports efficient writes and reads, whereas C1 to Ck are <em>immutable disk-resident</em> components sorted by key.</p>
<img class="align-center" src="/lsm-c0-ck.png" />
<blockquote>
<p><strong>Data structure choice for C0</strong>: The data structure for C0 should maintain the keys in the sorted order (for range queries) and provide efficient reads and writes. This data structure could be a <a href="https://docs.oracle.com/javase/8/docs/api/java/util/HashMap.html" target="_blank" rel="noopener">hashmap</a>
, a <a href="https://docs.oracle.com/javase/8/docs/api/java/util/TreeMap.html" target="_blank" rel="noopener">treemap</a>
 or a <a href="https://en.wikipedia.org/wiki/Red%E2%80%93black_tree" target="_blank" rel="noopener">red-black tree</a>
 or a <a href="https://en.wikipedia.org/wiki/Skip_list" target="_blank" rel="noopener">skip list</a>
. Of all these data structures, the Skip list is the one that supports versioned keys, the same key with different versions.</p>
</blockquote>
<p>Let&rsquo;s take a look at the overall flow of <code>put(key: []byte, value: []byte)</code> and <code>get(key: []byte)</code> operations in the LSM-tree.</p>
<p>Every <code>put(key, value)</code> in the LSM-tree adds the key-value pair in the C0 component, and after C0 is full, the entire data is flushed to disk. LSM-trees treat <code>delete(key)</code> as another <code>put</code>, which will put the key with a deleted marker.</p>
<p>After C0 is full, a new instance of C0 is created and the entire in-memory data is flushed to disk. All in-memory data consisting of key-value pairs is encoded in a byte array and written to disk. If the C1 component already exists on disk, the buffered content is merged with the contents of C1.</p>
<p>Because all the new writes are kept in-memory, they can get lost in case of a failure. The durability guarantee is ensured by using a <a href="https://martinfowler.com/articles/patterns-of-distributed-systems/wal.html" target="_blank" rel="noopener">WAL</a>
. Every <code>put(key, value)</code> <em>appends</em> the key-value pair to a WAL file and then writes the key-value pair to the C0 component. Appending to a WAL file is also a sequential write to disk.</p>
<p>Every <code>get(key)</code> in the LSM-tree goes through the RAM based component to disk components from C1 to Ck in the order. The <code>get(key)</code> operation first queries the C0 component, if the value for the key is not found, the search proceeds
to the disk resident component C1. This process continues until the value is found or all the disk resident components have been scanned. LSM-trees may need multiple reads for a point lookup. Hence, LSM-trees are most useful when inserts are more common than lookups.</p>
<p><strong>Quick summary</strong></p>
<blockquote>
<p>LSM-tree is a collection of exponentially increasing sized components, C0 to Ck. <br/> Writes go to WAL (on disk) -&gt; C0 (in RAM). <br/> After C0 is full, the entire data is flushed to disk. <br/> The get operation involves going through C0 to Ck.</p>
</blockquote>
<p>Let&rsquo;s look at the structure of LSM-tree in LevelDB to understand more on C0 to Ck components.</p>
<h3 id="leveldb">LevelDB</h3>
<p>LevelDB is a key-value storage engine based on LSM-tree. LevelDB maintains the following data structures:</p>
<ol>
<li>On-disk log file (WAL) to persist the writes</li>
<li>Two in-memory components called &ldquo;memtables&rdquo; (active and passive)</li>
<li>Seven levels of on-disk components called &ldquo;SSTable&rdquo; (Sorted string table)</li>
</ol>
<p>Every <code>put(key, value)</code> goes in a log file and the active in-memory memtable. Once the active memtable is full, LevelDB <em>switches to a new memtable and log file</em> to handle further writes.</p>
<p>The previously active memtable is stored as an immutable memtable in RAM and flushed to disk in the background. This flush to disk generates a new SSTable file (about 2 MB) at level-0 and discards the previous log file (WAL).</p>
<p>The size of all files in each level is limited and increases by a factor of ten with the level number. For example, the size limit of all files at L1 is 10 MB, while the limit of L2 is 100 MB.</p>
<p>In order to perform the <code>get(key)</code> operation, LevelDB performs the following steps:</p>
<ol>
<li>Perform <code>get</code> in the active memtable (RAM),</li>
<li>If not found, perform <code>get</code> in the immutable memtable (RAM),</li>
<li>If not found, perform <code>get</code> in the files from Level0 to Level6. LevelDB ensures that the keys do not overlap in the files from Level1 to Level6 whereas keys in the Level0 files can overlap.
<ol>
<li>This means that a <code>get</code> operation may involve multiple files in Level0 and one file at each level from Level1 to Level6</li>
</ol>
</li>
</ol>
<p><strong>LevelDB implements the in-memory components using <a href="https://en.wikipedia.org/wiki/Skip_list" target="_blank" rel="noopener">Skip list</a>
</strong>.</p>
<p>LevelDB stores keys in the memtable with versions (or tags). It is possible to insert the key &ldquo;Storage&rdquo; more than once; each time, it will have a different version. Such storage engines are called versioned storage engines.
Skip list is a natural data structure choice for building versioned stores because it will place the same key with different versions next to each other.
Below is the definition of <code>Add</code> method in LevelDB&rsquo;s memtable. The key-value pair and sequence number (u64) are encoded together.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C" data-lang="C"><span style="display:flex;"><span><span style="color:#8be9fd">void</span> MemTable<span style="color:#ff79c6">::</span><span style="color:#50fa7b">Add</span>(SequenceNumber s, ValueType type, <span style="color:#ff79c6">const</span> Slice<span style="color:#ff79c6">&amp;</span> key,
</span></span><span style="display:flex;"><span>                   <span style="color:#ff79c6">const</span> Slice<span style="color:#ff79c6">&amp;</span> value) {
</span></span><span style="display:flex;"><span>  <span style="color:#6272a4">// Format of an entry is concatenation of:
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>  <span style="color:#6272a4">//  key_size     : varint32 of internal_key.size()
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>  <span style="color:#6272a4">//  key bytes    : char[internal_key.size()]
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>  <span style="color:#6272a4">//  tag          : uint64((sequence &lt;&lt; 8) | type)
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>  <span style="color:#6272a4">//  value_size   : varint32 of value.size()
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>  <span style="color:#6272a4">//  value bytes  : char[value.size()]
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>  <span style="color:#8be9fd">size_t</span> key_size <span style="color:#ff79c6">=</span> key.<span style="color:#50fa7b">size</span>();
</span></span><span style="display:flex;"><span>  <span style="color:#8be9fd">size_t</span> val_size <span style="color:#ff79c6">=</span> value.<span style="color:#50fa7b">size</span>();
</span></span><span style="display:flex;"><span>  <span style="color:#8be9fd">size_t</span> internal_key_size <span style="color:#ff79c6">=</span> key_size <span style="color:#ff79c6">+</span> <span style="color:#bd93f9">8</span>;
</span></span><span style="display:flex;"><span>  <span style="color:#ff79c6">const</span> <span style="color:#8be9fd">size_t</span> encoded_len <span style="color:#ff79c6">=</span> <span style="color:#50fa7b">VarintLength</span>(internal_key_size) <span style="color:#ff79c6">+</span>
</span></span><span style="display:flex;"><span>                             internal_key_size <span style="color:#ff79c6">+</span> <span style="color:#50fa7b">VarintLength</span>(val_size) <span style="color:#ff79c6">+</span>
</span></span><span style="display:flex;"><span>                             val_size;
</span></span><span style="display:flex;"><span>  <span style="color:#8be9fd">char</span><span style="color:#ff79c6">*</span> buf <span style="color:#ff79c6">=</span> arena_.<span style="color:#50fa7b">Allocate</span>(encoded_len);
</span></span><span style="display:flex;"><span>  <span style="color:#8be9fd">char</span><span style="color:#ff79c6">*</span> p <span style="color:#ff79c6">=</span> <span style="color:#50fa7b">EncodeVarint32</span>(buf, internal_key_size);
</span></span><span style="display:flex;"><span>  std<span style="color:#ff79c6">::</span><span style="color:#50fa7b">memcpy</span>(p, key.<span style="color:#50fa7b">data</span>(), key_size);
</span></span><span style="display:flex;"><span>  p <span style="color:#ff79c6">+=</span> key_size;
</span></span><span style="display:flex;"><span>  <span style="color:#50fa7b">EncodeFixed64</span>(p, (s <span style="color:#ff79c6">&lt;&lt;</span> <span style="color:#bd93f9">8</span>) <span style="color:#ff79c6">|</span> type);
</span></span><span style="display:flex;"><span>  p <span style="color:#ff79c6">+=</span> <span style="color:#bd93f9">8</span>;
</span></span><span style="display:flex;"><span>  p <span style="color:#ff79c6">=</span> <span style="color:#50fa7b">EncodeVarint32</span>(p, val_size);
</span></span><span style="display:flex;"><span>  std<span style="color:#ff79c6">::</span><span style="color:#50fa7b">memcpy</span>(p, value.<span style="color:#50fa7b">data</span>(), val_size);
</span></span><span style="display:flex;"><span>  <span style="color:#50fa7b">assert</span>(p <span style="color:#ff79c6">+</span> val_size <span style="color:#ff79c6">==</span> buf <span style="color:#ff79c6">+</span> encoded_len);
</span></span><span style="display:flex;"><span>  table_.<span style="color:#50fa7b">Insert</span>(buf);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Let&rsquo;s understand the high-level architecture of LevelDB.</p>
<img class="align-center" src="/leveldb.png" />
<p>Let&rsquo;s spend a few minutes understanding an SSTable file&rsquo;s structure before we move on.</p>
<p>SSTables contain key-value pairs sorted by key. Key-value pairs are encoded before they can be written to a file. One encoding scheme could be to use <code>key-size</code>, followed by <code>value-size</code>, followed by the <code>actual key</code> and then the <code>actual value</code> as depicted in the following table:</p>
<table>
  <thead>
      <tr>
          <th><strong>Key size (u32)</strong></th>
          <th><strong>Value size (u32)</strong></th>
          <th><strong>Key ([]byte)</strong></th>
          <th><strong>Value ([]byte)</strong></th>
      </tr>
  </thead>
  <tbody>
  </tbody>
</table>
<p><em>We use <code>u32</code> type as an example for the key and the value size. Key-size and value-size would be represented using fixed-size data types like <code>u16</code> or <code>u32</code></em>.</p>
<p>A naive way to get the value for a key in an SSTable would be to read the entire SSTable file, match each key and return the value if the matching key is found.</p>
<blockquote>
<p><strong>How do you read a single key-value pair from an SSTable file that follows the encoding mentioned above scheme</strong>? To read one key-value pair from an SSTable file, we need to read the first four bytes (<code>u32</code>) to get the key size, next four bytes to get the value size, then read the number of bytes equal to the key size to get the key and finally read the number of bytes equal to the value size to get the value.</p>
</blockquote>
<p>SSTable files are organized into blocks (or sections). SSTable files in all the LSM-tree based storage engines typically include <code>index-block</code> + <code>bloom-filter-block</code> + <code>data-block</code>. <em>Imagine all these blocks as byte arrays ranging from offset to offset.</em></p>
<p><strong>Index-block</strong> contains the key-offset pairs in the sorted order by key. The offset here is the offset of the key-value pair in the data block of the SSTable file.</p>
<p><strong>Bloom filter block</strong> contains the bloom filter byte array of all the keys present in the SSTable file</p>
<p><strong>Data block</strong> contains the actual data; the key-value pairs in the sorted order by key</p>
<blockquote>
<p>A Bloom filter is a probabilistic data structure used to test whether an element is a set member. A bloom filter can query against large amounts of data and return either “possibly in the set” or “definitely not in the set”. More information on bloom filter is available <a href="/en/blog/bloom_filter/">here</a>
.</p>
</blockquote>
<p>Let&rsquo;s take a quick look at compaction.</p>
<h4 id="compaction">Compaction</h4>
<p>To maintain the size limit of each level, once the total size of a level L<sub>i</sub> exceeds its limit, the compaction thread will choose one file from L<sub>i</sub>, merge sort with all the overlapped files of L<sub>i+1</sub>, and generate new L<sub>i+1</sub> SSTable files.
The compaction process involves:</p>
<ul>
<li>Loading SSTable files in memory (block by block),</li>
<li>Performing merge sort on the files,</li>
<li>Removing the deleted keys and writing back those files. The compaction thread continues until all levels are within their size limits.</li>
</ul>
<p>Compaction is a CPU &amp; IO-intensive process and the reason for high write-amplification in LevelDB.</p>
<p><strong>Quick summary</strong></p>
<blockquote>
<p>LevelDB uses WAL, memtables and SSTables as its data structures. <br/> Memtable is implemented using Skip list <br/> SSTables are sorted string tables and organized into levels, Level0 to Level6. <br/> SSTables are organized into index-block, bloom-filter, and data blocks. <br/> Puts go to WAL and the active memtable. <br/> Gets go to active memtable -&gt; immutable memtable -&gt; SSTables.</p>
</blockquote>
<p>Let&rsquo;s now understand &ldquo;read and write amplification&rdquo;.</p>
<h3 id="read-write-amplification">Read Write amplification</h3>
<p>HDDs, SDDs and NVMe SSDs are block storage devices. The smallest unit of exchange between an application and a block storage device is a block. Usually the size of a block is 4KB.
Let&rsquo;s assume a key/value storage engine on a block storage device like HDD. When the key/value storage engine wants to fetch the value for a 128 bytes key, it must do the following:</p>
<ul>
<li>read the entire block containing the value from the underlying device (<em>ignore how that block is located</em>),</li>
<li>allocate a buffer in-memory to hold the result</li>
</ul>
<p>Even when making a minor update say, 128 bytes, the storage engine needs to do the following:</p>
<ul>
<li>read the entire block containing those 128 bytes into a memory buffer,</li>
<li>update 128 bytes in the buffer,</li>
<li>write the entire block to the underlying device.</li>
</ul>
<blockquote>
<p>Block IO involves transferring an entire block of data, typically 4K bytes at a time. So the task to read 128 bytes would require reading at least one block of 4K bytes.</p>
</blockquote>
<p>The storage engine has to read (and write to) more than what is requested by the user. This results in &ldquo;amplification&rdquo;. Both the reads and the writes get amplified.</p>
<p><strong>Read amplification</strong> is the ratio of the amount of data read from the storage device and the amount of data requested by the user. In the above example, read amplification is 32 (<code>4*1024 bytes / 128 bytes</code>).</p>
<p><strong>Write amplification</strong> is the ratio of the amount of data written to the storage device and the amount of data requested by the user. In the above example, write amplification is 32 (<code>4*1024 bytes / 128 bytes</code>).</p>
<p><strong>Quick summary</strong></p>
<blockquote>
<p>The smallest unit of data exchange between an application and a block storage device is a block, usually 4KB in size. <br/> Read/Write amplification is the amount of data read from (or written to) the storage device and the amount of data requested by the user.</p>
</blockquote>
<h3 id="analysis-of-read-write-amplification-in-leveldb">Analysis of Read Write amplification in LevelDB</h3>
<p>Let&rsquo;s analyze the read-and-write amplification in LevelDB.</p>
<p><strong>Let&rsquo;s start with read amplification</strong>.</p>
<p><em>LevelDB ensures that the keys do not overlap in the files from Level1 to Level6 whereas keys in the Level0 files can overlap.</em></p>
<p>Let&rsquo;s assume that the value for a key is not found in the active and the immutable memtable. Now, LevelDB needs to read SSTable files. In the worst case, LevelDB needs to check eight files in Level0, and one file for each of the remaining six levels: <strong>a total of 14 files</strong>.</p>
<p>To find the value for a key within an SSTable file, LevelDB needs to read multiple metadata (or index) sections within the file. Specifically, the amount of data read is: 16-KB index section, a 4-KB bloom-filter section, and a 4-KB data section <code>(24KB)</code>.</p>
<blockquote>
<p>The read amplification in LevelDB is 336 (<code>14 files * 24KB</code>). Another way to state this is: &ldquo;LevelDB amplifies the reads by 336 times in the worst case&rdquo;.</p>
</blockquote>
<p><strong>Let&rsquo;s analyze the write amplification</strong>.</p>
<p>LSM-tree based storage engines must perform file merges during <a href="#compaction">compaction</a>
.</p>
<p>In LevelDB, the size of the level L<sub>i</sub> is ten times the size of the level L<sub>i-1</sub> (Size of Level2 is 100MB whereas the size of Level1 is 10MB). To merge a file from the level L<sub>i-1</sub> to L<sub>i</sub>, LevelDB may end up reading ten files from
the level L<sub>i</sub> in the worst case and write back those ten files after sorting. So, the write amplification of moving a file from one level to the next can be as high as ten.</p>
<blockquote>
<p>In the worst case, a file may move from Level0 to Level6 through compaction steps. The total write amplification in the worst case can be over 50 (write amplification is 10 for each level between L1 to L6).</p>
</blockquote>
<p><em>We ignore the cost of moving a file from Level0 to Level1</em>.</p>
<h4 id="why-does-leveldb-check-only-one-sstable-file-at-each-level-from-level1-to-level6-for-a-read-operation">Why does LevelDB check only one SSTable file at each level from Level1 to Level6, for a read operation?</h4>
<p><em>LevelDB ensures that the keys do not overlap in the files from Level1 to Level6</em>. This means a range-based search on keys can be done in RAM to identify an SSTable at each level to search.</p>
<p>This approach can be highlighted with the following pseudocode:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-golang" data-lang="golang"><span style="display:flex;"><span>    <span style="color:#6272a4">//Compare the incoming key against the biggest keys in all the SSTable files at each level. 
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#6272a4">//BiggestKey can be maintained in RAM for each SSTable file from level &gt;= 1.
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>	idx <span style="color:#ff79c6">:=</span> sort.<span style="color:#50fa7b">Search</span>(<span style="color:#8be9fd;font-style:italic">len</span>(level.table_files), <span style="color:#8be9fd;font-style:italic">func</span>(index <span style="color:#8be9fd">int</span>) <span style="color:#8be9fd">bool</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#ff79c6">return</span> <span style="color:#50fa7b">CompareKeys</span>(level.table_files[index].<span style="color:#50fa7b">BiggestKey</span>(), key) <span style="color:#ff79c6">&gt;=</span> <span style="color:#bd93f9">0</span> 
</span></span><span style="display:flex;"><span>	})
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">if</span> idx <span style="color:#ff79c6">&gt;=</span> <span style="color:#8be9fd;font-style:italic">len</span>(level.table_files) {
</span></span><span style="display:flex;"><span>		<span style="color:#6272a4">// Given key is strictly &gt; than every element we have.
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>		<span style="color:#ff79c6">return</span> <span style="color:#ff79c6">nil</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">return</span> level.table_files[idx]
</span></span></code></pre></div><p>Hence, LevelDB has to search one SSTable file at each level from Level1 to Level6 in the worst case.</p>
<h4 id="why-is-the-size-of-the-index-section-16kb">Why is the size of the index section 16KB?</h4>
<p>SSTables can contain more than one metadata or index section. Even if the index section is just 1KB, Block IO involves reading the entire disk block from the underlying storage. LevelDB has four index sections; each section involves reading a 4KB disk block. Hence, the data that is actually read for the index section is 16KB.</p>
<h4 id="why-is-the-size-of-the-data-section-just-4kb">Why is the size of the data section just 4KB?</h4>
<p>The data section can be huge, but LevelDB needs to read just the 4KB data section to find the value for a key. The steps include:</p>
<ul>
<li>LevelDB will load the index section to identify the position of the bloom-filter section.
<ul>
<li>Index section (or the index block) contains metadata, and one of the metadata items could be the beginning offset of the bloom-filter block (the other could be the offset of the keys in the data block as mentioned earlier).</li>
</ul>
</li>
<li>LevelDB will load the bloom-filter section and skip the file if the key is not present.</li>
<li>If the bloom filter indicates that the key may be present, LevelDB will identify the offset of the key from the index section.</li>
<li>LevelDB jumps to the identified offset within the data section. With Block IO, the entire block containing the offset is read. So, LevelDB ends up reading 4KB of the data block.</li>
</ul>
<p><em>I am using the term section with index, bloom-filter and data to avoid confusing it with the disk block</em>.</p>
<h4 id="why-do-we-need-an-index-block-in-an-sstable-file">Why do we need an index block in an SSTable file?</h4>
<p>In a key-value storage engine, the value is considered to be much bigger than the key.</p>
<p>Index block will contain the key/value-offset pairs sorted by keys. Let&rsquo;s assume 10,000 keys in an SSTable file where each key is 100 bytes long. This means each key-offset pair will take <code>104 bytes</code> (<code>100 bytes for the key + 4 bytes for the offset</code>, ignoring the encoding).
So, the total size of the index block would be around 0.99 MB <code>(((104 * 10,000)/1024)/1024)</code>. To get the value for a key, the storage engine will need to read ~1 MB of index block, and if the key is found, a random seek to the identified offset within the data block will be needed.</p>
<p>If the index block were not there, the same get operation would have happened against the data block. Assuming the size of a single value to be 1024 bytes, we will have around 10.71 MB <code>((((100 + 1024) * 10,000)/1024)/1024)</code> as the size of the data block.</p>
<p><strong>Quick summary</strong></p>
<blockquote>
<p>The <strong>read amplification in LevelDB is 336</strong> and the <strong>write amplification can be over 50</strong>, in the worst case. <br/> A key idea while designing a storage engine is to minimize the read and write amplification to reduce IO latency. Also, SSDs can wear out through repeated writes, and the high write amplification in LSM-trees can significantly reduce device lifetime.</p>
</blockquote>
<h3 id="ssd-considerations-when-designing-a-storage-engine">SSD considerations when designing a storage engine</h3>
<p>There are fundamental differences between SSDs and HDDs which should be considered when designing a storage engine. Let&rsquo;s look at some of the most important considerations:</p>
<ol>
<li>SSDs can wear out through repeated writes, the high write amplification in LSM-trees can significantly reduce the device lifetime.</li>
<li>SSDs offer a large degree of internal parallelism</li>
</ol>
<p>Point 1 means we should try to <strong>reduce the write amplification</strong> when designing a storage engine for SSD-conscious storage. We have already seen that the <a href="#analysis-of-read-write-amplification-in-leveldb">compaction</a>
 process is the source of high write-application in LSM-tree based storage engines.</p>
<p>Point 2 means we should try to <strong>leverage the parallelism offered by SSDs</strong> when performing IO operations. Let&rsquo;s look at the below graph. For the request size &gt;= 64KB, the aggregate throughput of random reads with 32 threads matches the sequential read throughput.</p>
<figure>
    <img class="align-center" src="/SSD-parallelism.png" />
</figure>
<p><strong>Sequential and Random Reads on SSD</strong>. This figure shows the sequential and random read performance for various request sizes on a modern SSD device. All requests are issued to a 100-GB file on ext4.</p>
<p><strong>Quick summary</strong></p>
<blockquote>
<p>When designing a storage engine for SSDs, try to reduce the write-amplification and leverage the internal parallelism offered by SSDs.</p>
</blockquote>
<p>With these considerations, let&rsquo;s understand WiscKey proposal.</p>
<h3 id="wisckey-proposal">WiscKey proposal</h3>
<p>WiscKey proposes four key ideas:</p>
<ol>
<li>Separate values from keys, keeping only the keys in the LSM-tree, putting values in a separate value-log.</li>
<li>Leverage the parallel random read characteristic of SSDs during range queries.</li>
<li>Introduce garbage collection to remove values corresponding to deleted keys from value-log.</li>
<li>Remove LSM-tree log (WAL log) without sacrificing consistency (under <a href="#optimizations-offered-by-wisckey">Optimizations</a>
).</li>
</ol>
<p>Let&rsquo;s discuss each of these ideas one by one.</p>
<h4 id="separate-values-from-keys">Separate values from keys</h4>
<p>Compaction is the reason for the significant performance cost in LSM-trees. Multiple SSTable files are read in-memory during compaction, sorted, and written back. This is also the reason
for the high write amplification in LevelDB. If we look at the compaction process carefully, we will realize that this process only needs to sort the keys, while values can be managed separately.
Since keys are usually smaller than values, compacting only keys could significantly reduce the amount of data needed during the sorting.</p>
<p><em>In WiscKey, only the location of the value is stored in the LSM-tree along with the key, while the actual values are stored in a separate value-log file.</em></p>
<p>The <code>put(key, value)</code> operation in WiscKey modifies the original <code>put</code> flow. Every <code>put(key, value)</code> in the WiscKey adds the <code>key-value pair</code> in the <code>value-log</code> and then adds the <code>key</code> along with the value-log offset in the memtable.
Converting the active memtable to the immutable memtable, flushing the active memtable to disk and performing the compaction process in the background remain the same.</p>
<blockquote>
<p>Memtables and SSTables in WiscKey contain keys and the key-value pair offset from the value-log. Given, keys are smaller than values, the amount of data needed during compaction is significantly reduced.</p>
</blockquote>
<p>Let&rsquo;s look at the flow of the <code>get(key)</code> operation.</p>
<ol>
<li>Perform <code>get</code> in the active memtable (RAM),</li>
<li>If not found, perform <code>get</code> in the immutable memtable (RAM),</li>
<li>If not found, perform <code>get</code> in the SSTable files.</li>
</ol>
<p>If the <code>get</code> operation finds the key, a random seek to the key-value pair offset needs to be performed in the value-log to get the value.
This requires an additional IO for every <code>get</code> operation. The research paper claims that the LSM-tree of Wisckey is a lot smaller than LevelDB, a lookup may search fewer levels of table files, and a significant portion of the LSM-tree can be easily cached in memory.</p>
<blockquote>
<p>BadgerDB implements the WiscKey paper, but it makes a minor modification to <code>put</code> and the <code>get</code> operations. If the value size is less than some threshold, the value will be put in the memtable else the value-offset will be put in the memtable. If the key is found during the <code>get</code> operation, BadgerDB loads the value from the value-log if the retrieved value is a value-offset. SSTables always contain the value-offset.</p>
</blockquote>
<p>A key in WiscKey will be deleted from the LSM-tree but the value-log remains untouched. WiscKey proposes <a href="#introduce-garbage-collection">garbage collection</a>
 to remove invalid (or dangling) values from value-log.</p>
<h4 id="leverage-the-internal-parallelism-of-ssds">Leverage the internal parallelism of SSDs</h4>
<p>All the modern storage engines provide support for range queries. LevelDB provides the clients with an <code>iterator-based</code> interface with <code>Seek(key)</code>, <code>Next()</code>, <code>Prev()</code>, <code>Key()</code> and <code>Value()</code> operations. To scan a range of key-value pairs, the client can first <code>Seek(key)</code> to the starting key, then call <code>Next()</code> or <code>Prev()</code> to search keys one by one. To retrieve the key or the value of the current iterator position, the client calls <code>Key()</code> or <code>Value()</code>, respectively.</p>
<p>In LevelDB, since keys and values are stored together and sorted, a range query can sequentially read key-value pairs from SSTable files as shown in the image below.</p>
<img class="align-center" src="/sequential-reads-leveldb.png" />
<p>However, since keys and values are stored separately in WiscKey, range queries require random reads (from value-log), and are inefficient.</p>
<img class="align-center" src="/random-reads-wisckey.png" />
<p>Wisckey leverages the same iterator-based interface for range queries as LevelDB. To make range queries efficient, WiscKey leverages the parallel I/O characteristic of SSD devices to prefetch values from the value-log during range queries.</p>
<p>WiscKey tracks the access pattern of a range query. Once a contiguous sequence of key-value pairs is requested, WiscKey reads the following keys from the LSM-tree sequentially. The values corresponding to those prefetched keys are resolved in parallel (using multiple threads) from the value-log.</p>
<blockquote>
<p>BadgerDB uses <code>PrefetchSize (int)</code> and <code>PrefetchValues (bool)</code> in the <code>IteratorOptions</code> struct [<code>iterator.go</code>] to decide if the values have to be prefetched. The <code>DefaultIteratorOptions</code> defines 100 as the prefetch size.</p>
</blockquote>
<h4 id="introduce-garbage-collection">Introduce garbage collection</h4>
<p>Wisckey stores only the keys in the LSM-tree and the values are managed separately. During compaction, the deleted keys will be removed from SSTable files but the values corresponding to the deleted keys will still be present in the value-log. Let&rsquo;s call those values as dangling values.
To deal with dangling values, WiscKey proposes a lightweight garbage collector to reclaim free space in the value-log.</p>
<p>Let&rsquo;s look at the structure of the value-log. Every entry in the value-log contains <code>key-size</code>, <code>value-size</code>, <code>key</code> and the <code>value</code>. The <code>head</code> end of this log corresponds to the end of the value-log where new values will be appended and the <code>tail</code> of this log is where garbage collection starts freeing space whenever it is triggered.
Only the part of the value-log between the tail and the head offset contains valid values and will be searched during lookups.</p>
<img class="align-center" src="/value-log.png" />
<p>Garbage collection involves the following steps:</p>
<ol>
<li>WiscKey reads a chunk of key-value pairs (several MBs) from the <code>tail</code> offset of the value-log. It then finds which of those values are valid by querying the LSM-tree.</li>
<li>After all the valid key-value pairs are identified, the entire byte array containing the valid key-value pairs is appended to the end of the log.</li>
<li>To avoid losing any data in case a crash happens during garbage collection, WiscKey calls <code>fsync</code> on the value-log.</li>
<li>WiscKey needs to add the updated value’s addresses to the LSM-tree. So, it adds the key &amp; value-offset pairs to the LSM-tree along with the current tail offset. The tail is stored in the LSM-tree as <code>&lt;'tail', tail-value-log-offset&gt;</code>.</li>
<li>Finally, the free space is reclaimed and the head offset is stored in the LSM-tree.</li>
</ol>
<p><strong>Quick summary</strong></p>
<blockquote>
<p>WiscKey separates values from keys in the LSM-tree. LSM-tree contains keys and the offsets of the key-value pair from the value-log. This reduces the write-amplification during compaction. </br> WiscKey leverages the internal parallelism offered by SSDs, during range queries. <br/> Wisckey introduces garbage collection to remove dangling values from the value-log.</p>
</blockquote>
<p>Let&rsquo;s discuss various optimizations proposed in the WiscKey paper.</p>
<h3 id="optimizations-offered-by-wisckey">Optimizations offered by WiscKey</h3>
<p>WiscKey offers two optimizations:</p>
<ol>
<li><strong>Value-Log Write Buffer</strong>: to buffer the key-value pairs before they are written to the value-log</li>
<li><strong>Remove LSM-tree log</strong>: use value-log as recovery mechanism</li>
</ol>
<h4 id="value-log-write-buffer">Value-Log Write Buffer</h4>
<p>For each <code>put(key, value)</code> operation, WiscKey needs to append the key-value pair in the value-log. Every <code>put</code> operation will require a <code>write</code> system call.</p>
<p>To reduce the write-overhead, WiscKey buffers the incoming key-value pairs in memory. The buffer is flushed to value-log only when the buffer size exceeds a threshold or when the user requests a synchronous insertion.
This requires a change in the <code>get</code> operation.</p>
<p>Assume that a <code>get</code> operation finds the value-offset in the active memtable. The system needs to look up the value-offset in the value-log to get the value. With the introduction of the value-log buffer,
the lookup operation will be performed in the value-log buffer first and if the value-log offset is not found in the buffer, it actually reads from the value-log.</p>
<p><em>This optimization means that the buffered data can be lost during a crash.</em></p>
<h4 id="removal-of-lsm-tree-log">Removal of LSM-tree Log</h4>
<p>The value-log is storing the entire key-value pair. If a crash happens before the keys are persistent in the LSM-tree (and after they have been written to the value-log), they can be recovered by scanning the value-log.
In order to optimize the recovery of the LSM-tree from the value-log, the <code>head</code> offset of the value-log is periodically stored in the LSM-tree as <code>&lt;'head', head-value-log-offset&gt;</code>.
When the database is opened, WiscKey starts the value-log scan from the most recent head position stored in the LSM-tree, and continues scanning until the end of the value-log.
So, removing the LSM-tree log is a safe optimization.</p>
<h3 id="reference-implementation-of-wisckey">Reference implementation of WiscKey</h3>
<p><a href="https://github.com/dgraph-io/badger" target="_blank" rel="noopener">BadgerDB</a>
 is an implementation of the WiscKey paper. We will briefly look at the <code>put</code> and the <code>get</code> implementations of BadgerDB.</p>
<p>Let&rsquo;s start with <code>put(key, value)</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-golang" data-lang="golang"><span style="display:flex;"><span><span style="color:#6272a4">//Fields ommitted
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span><span style="color:#8be9fd;font-style:italic">type</span> request <span style="color:#8be9fd;font-style:italic">struct</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#6272a4">// Input values
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>	Entries []<span style="color:#ff79c6">*</span>Entry
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	Ptrs []valuePointer
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">type</span> Entry <span style="color:#8be9fd;font-style:italic">struct</span> {
</span></span><span style="display:flex;"><span>	Key       []<span style="color:#8be9fd">byte</span>
</span></span><span style="display:flex;"><span>	Value     []<span style="color:#8be9fd">byte</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">type</span> valuePointer <span style="color:#8be9fd;font-style:italic">struct</span> {
</span></span><span style="display:flex;"><span>	Fid    <span style="color:#8be9fd">uint32</span>
</span></span><span style="display:flex;"><span>	Len    <span style="color:#8be9fd">uint32</span>
</span></span><span style="display:flex;"><span>	Offset <span style="color:#8be9fd">uint32</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">//Code ommitted
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span><span style="color:#8be9fd;font-style:italic">func</span> (db <span style="color:#ff79c6">*</span>DB) <span style="color:#50fa7b">writeRequests</span>(requests []<span style="color:#ff79c6">*</span>request) <span style="color:#8be9fd">error</span> {
</span></span><span style="display:flex;"><span>	db.opt.<span style="color:#50fa7b">Debugf</span>(<span style="color:#f1fa8c">&#34;writeRequests called. Writing to value log&#34;</span>)
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>	<span style="color:#6272a4">//write the requests to the value log file
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>	err <span style="color:#ff79c6">:=</span> db.vlog.<span style="color:#50fa7b">write</span>(requests) 
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">if</span> err <span style="color:#ff79c6">!=</span> <span style="color:#ff79c6">nil</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#50fa7b">done</span>(err)
</span></span><span style="display:flex;"><span>		<span style="color:#ff79c6">return</span> err
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">for</span> _, request <span style="color:#ff79c6">:=</span> <span style="color:#ff79c6">range</span> requests {
</span></span><span style="display:flex;"><span>		<span style="color:#6272a4">//write a single request to the LSM-tree
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>		<span style="color:#ff79c6">if</span> err <span style="color:#ff79c6">:=</span> db.<span style="color:#50fa7b">writeToLSM</span>(request); err <span style="color:#ff79c6">!=</span> <span style="color:#ff79c6">nil</span> {  
</span></span><span style="display:flex;"><span>			<span style="color:#50fa7b">done</span>(err)
</span></span><span style="display:flex;"><span>			<span style="color:#ff79c6">return</span> y.<span style="color:#50fa7b">Wrap</span>(err, <span style="color:#f1fa8c">&#34;writeRequests&#34;</span>)
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">return</span> <span style="color:#ff79c6">nil</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>BadgerDB implements <a href="https://dl.acm.org/doi/abs/10.1145/2168836.2168853" target="_blank" rel="noopener">snapshot transaction isolation</a>
. Let&rsquo;s assume the <code>commit()</code> method on the transaction is invoked. The commit operation results in calling the <code>writeRequests</code>
method on <code>db</code> through a single goroutine in a fashion that is very much similar to a <a href="https://martinfowler.com/articles/patterns-of-distributed-systems/singular-update-queue.html" target="_blank" rel="noopener">singular update queue</a>
.</p>
<p>As a part of this method, the key-value pairs are written to the value-log and then each request is written to the LSM-tree.</p>
<p>Let&rsquo;s look at the <code>writeToLSM</code> method to understand the content of the memtable.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-golang" data-lang="golang"><span style="display:flex;"><span><span style="color:#6272a4">//Code ommitted
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span><span style="color:#8be9fd;font-style:italic">func</span> (db <span style="color:#ff79c6">*</span>DB) <span style="color:#50fa7b">writeToLSM</span>(reqest <span style="color:#ff79c6">*</span>request) <span style="color:#8be9fd">error</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//Iterate through all the entries in the request
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>	<span style="color:#ff79c6">for</span> i, entry <span style="color:#ff79c6">:=</span> <span style="color:#ff79c6">range</span> reqest.Entries {
</span></span><span style="display:flex;"><span>		<span style="color:#8be9fd;font-style:italic">var</span> err <span style="color:#8be9fd">error</span>
</span></span><span style="display:flex;"><span>		<span style="color:#ff79c6">if</span> db.opt.managedTxns <span style="color:#ff79c6">||</span> entry.<span style="color:#50fa7b">skipVlogAndSetThreshold</span>(db.<span style="color:#50fa7b">valueThreshold</span>()) {
</span></span><span style="display:flex;"><span>			<span style="color:#6272a4">//Write the entire key and the value in the memtable. 
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>			<span style="color:#6272a4">//Memtable is implemented using Skip list 
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>			err = db.memtable.<span style="color:#50fa7b">Put</span>(entry.Key,
</span></span><span style="display:flex;"><span>				y.ValueStruct{
</span></span><span style="display:flex;"><span>					Value: entry.Value,
</span></span><span style="display:flex;"><span>					Meta:      entry.meta <span style="color:#ff79c6">&amp;^</span> bitValuePointer,
</span></span><span style="display:flex;"><span>					UserMeta:  entry.UserMeta,
</span></span><span style="display:flex;"><span>					ExpiresAt: entry.ExpiresAt,
</span></span><span style="display:flex;"><span>				})
</span></span><span style="display:flex;"><span>		} <span style="color:#ff79c6">else</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#6272a4">// Write the pointer to the memtable.
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>			err = db.memtable.<span style="color:#50fa7b">Put</span>(entry.Key,
</span></span><span style="display:flex;"><span>				y.ValueStruct{
</span></span><span style="display:flex;"><span>					Value:     reqest.Ptrs[i].<span style="color:#50fa7b">Encode</span>(),
</span></span><span style="display:flex;"><span>					Meta:      entry.meta | bitValuePointer,
</span></span><span style="display:flex;"><span>					UserMeta:  entry.UserMeta,
</span></span><span style="display:flex;"><span>					ExpiresAt: entry.ExpiresAt,
</span></span><span style="display:flex;"><span>				})
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>		<span style="color:#ff79c6">if</span> err <span style="color:#ff79c6">!=</span> <span style="color:#ff79c6">nil</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#ff79c6">return</span> y.<span style="color:#50fa7b">Wrapf</span>(err, <span style="color:#f1fa8c">&#34;while writing to memTable&#34;</span>)
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">if</span> db.opt.SyncWrites {
</span></span><span style="display:flex;"><span>	    <span style="color:#6272a4">//Memtable contains both a WAL and a skip list. 
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>	    <span style="color:#6272a4">//Sync the writes to the WAL associated with the current memtable. 
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>		<span style="color:#ff79c6">return</span> db.memtable.<span style="color:#50fa7b">SyncWAL</span>()
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">return</span> <span style="color:#ff79c6">nil</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">func</span> (e <span style="color:#ff79c6">*</span>Entry) <span style="color:#50fa7b">skipVlogAndSetThreshold</span>(threshold <span style="color:#8be9fd">int64</span>) <span style="color:#8be9fd">bool</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">if</span> e.valThreshold <span style="color:#ff79c6">==</span> <span style="color:#bd93f9">0</span> {
</span></span><span style="display:flex;"><span>		e.valThreshold = threshold
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">return</span> <span style="color:#8be9fd;font-style:italic">int64</span>(<span style="color:#8be9fd;font-style:italic">len</span>(e.Value)) &lt; e.valThreshold
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The method <code>writeToLSM</code> writes the entire key-value pair in the memtable if the size of the value is less than some threshold, else the encoded value of the <code>value pointer</code> is written to the memtable. <code>ValuePointer</code>
references the key-value pair offset in a value-log.</p>
<p>Let&rsquo;s look at the <code>get(key)</code> method.</p>
<blockquote>
<p><strong>BadgerDB maintains an array of immutable memtables to optimize reads.</strong>
The <code>get</code> operation searches the active memtable and if the key is not found, it searches the inactive (or immutable) memtables in the reverse order (the newest immutable memtable to the oldest immutable memtable). This results in more memory pressure but to avoid GC from scanning the memory occupied by memtables, BadgerDB implements <a href="https://github.com/dgraph-io/badger/blob/main/skl/skl.go" target="_blank" rel="noopener">Skip list</a>
 over a byte array.</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-golang" data-lang="golang"><span style="display:flex;"><span><span style="color:#6272a4">//Code ommitted
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span><span style="color:#8be9fd;font-style:italic">type</span> ValueStruct <span style="color:#8be9fd;font-style:italic">struct</span> {
</span></span><span style="display:flex;"><span>	Meta      <span style="color:#8be9fd">byte</span>
</span></span><span style="display:flex;"><span>	UserMeta  <span style="color:#8be9fd">byte</span>
</span></span><span style="display:flex;"><span>	ExpiresAt <span style="color:#8be9fd">uint64</span>
</span></span><span style="display:flex;"><span>	Value     []<span style="color:#8be9fd">byte</span>
</span></span><span style="display:flex;"><span>	Version <span style="color:#8be9fd">uint64</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">func</span> (txn <span style="color:#ff79c6">*</span>Txn) <span style="color:#50fa7b">Get</span>(key []<span style="color:#8be9fd">byte</span>) (item <span style="color:#ff79c6">*</span>Item, rerr <span style="color:#8be9fd">error</span>) {    
</span></span><span style="display:flex;"><span>	item = <span style="color:#8be9fd;font-style:italic">new</span>(Item)
</span></span><span style="display:flex;"><span>	seek <span style="color:#ff79c6">:=</span> y.<span style="color:#50fa7b">KeyWithTs</span>(key, txn.readTs)
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>	<span style="color:#6272a4">//Get the valueStruct corresponding to the key.
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>	<span style="color:#6272a4">//db.get will perform a get operation in all the memtables (active and all the immutable memtables), 
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>	<span style="color:#6272a4">//if the key is not found, it will perform a get across all the levels. 
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>	valueStruct, err <span style="color:#ff79c6">:=</span> txn.db.<span style="color:#50fa7b">get</span>(seek)
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">if</span> valueStruct.Value <span style="color:#ff79c6">==</span> <span style="color:#ff79c6">nil</span> <span style="color:#ff79c6">&amp;&amp;</span> valueStruct.Meta <span style="color:#ff79c6">==</span> <span style="color:#bd93f9">0</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#ff79c6">return</span> <span style="color:#ff79c6">nil</span>, ErrKeyNotFound
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">if</span> <span style="color:#50fa7b">isDeletedOrExpired</span>(valueStruct.Meta, valueStruct.ExpiresAt) {
</span></span><span style="display:flex;"><span>		<span style="color:#ff79c6">return</span> <span style="color:#ff79c6">nil</span>, ErrKeyNotFound
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//if the key exists, return an item. 
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#6272a4">//Item will abstract the idea of fetching the value from the value-log   
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>	item.key = key
</span></span><span style="display:flex;"><span>	item.version = valueStruct.Version
</span></span><span style="display:flex;"><span>	item.meta = valueStruct.Meta
</span></span><span style="display:flex;"><span>	item.userMeta = valueStruct.UserMeta
</span></span><span style="display:flex;"><span>	item.vptr = y.<span style="color:#50fa7b">SafeCopy</span>(item.vptr, valueStruct.Value)
</span></span><span style="display:flex;"><span>	item.txn = txn
</span></span><span style="display:flex;"><span>	item.expiresAt = valueStruct.ExpiresAt
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">return</span> item, <span style="color:#ff79c6">nil</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>Get(key)</code> method in the transaction does two things:</p>
<ol>
<li>Invokes the <code>get</code> method of the <code>db</code> abstraction to get an instance of <code>ValueStruct</code> (represents a value)</li>
<li>If the key exists, it returns an <code>Item</code>. <code>ValueStruct</code> may or may not contain the value, so <code>Item</code> abstraction ensures that the value is fetched from the value-log if needed.</li>
</ol>
<p>Let&rsquo;s look at the method <code>yieldItemValue</code> in the <code>Item</code>. The idea is to decode the value pointer (get the instance of <code>valuePointer</code> back from the byte array) and perform a random read
operation in the value-log.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-golang" data-lang="golang"><span style="display:flex;"><span><span style="color:#6272a4">//Code ommitted
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span><span style="color:#8be9fd;font-style:italic">func</span> (item <span style="color:#ff79c6">*</span>Item) <span style="color:#50fa7b">yieldItemValue</span>() ([]<span style="color:#8be9fd">byte</span>, <span style="color:#8be9fd;font-style:italic">func</span>(), <span style="color:#8be9fd">error</span>) {
</span></span><span style="display:flex;"><span>	key <span style="color:#ff79c6">:=</span> item.<span style="color:#50fa7b">Key</span>() <span style="color:#6272a4">// No need to copy.
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>	<span style="color:#ff79c6">if</span> !item.<span style="color:#50fa7b">hasValue</span>() {
</span></span><span style="display:flex;"><span>		<span style="color:#ff79c6">return</span> <span style="color:#ff79c6">nil</span>, <span style="color:#ff79c6">nil</span>, <span style="color:#ff79c6">nil</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#8be9fd;font-style:italic">var</span> vp valuePointer
</span></span><span style="display:flex;"><span>	vp.<span style="color:#50fa7b">Decode</span>(item.vptr)
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>	db <span style="color:#ff79c6">:=</span> item.txn.db
</span></span><span style="display:flex;"><span>	<span style="color:#6272a4">//Read the value from the value log. This is a random seek in the value-log.
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>	result, cb, err <span style="color:#ff79c6">:=</span> db.vlog.<span style="color:#50fa7b">Read</span>(vp, item.slice) 
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">...</span>.
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The article has already gone too long, but I would like to put a short mention of the <code>iterator</code> implementation in BadgerDB.</p>
<p>BadgerDB provides a <code>NewIterator(opt IteratorOptions)</code> method that returns an iterator object.</p>
<p>The challenge is: where should the iterator point to? Should it point to the active memtable? Or, which of the N immutable memtables or M SSTable files should it point to?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-golang" data-lang="golang"><span style="display:flex;"><span><span style="color:#6272a4">//Code ommitted
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span><span style="color:#8be9fd;font-style:italic">func</span> (txn <span style="color:#ff79c6">*</span>Txn) <span style="color:#50fa7b">NewIterator</span>(opt IteratorOptions) <span style="color:#ff79c6">*</span>Iterator {
</span></span><span style="display:flex;"><span>    tables, decr <span style="color:#ff79c6">:=</span> txn.db.<span style="color:#50fa7b">getMemTables</span>()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">for</span> i <span style="color:#ff79c6">:=</span> <span style="color:#bd93f9">0</span>; i &lt; <span style="color:#8be9fd;font-style:italic">len</span>(tables); i<span style="color:#ff79c6">++</span> {
</span></span><span style="display:flex;"><span>		iters = <span style="color:#8be9fd;font-style:italic">append</span>(iters, tables[i].skiplist.<span style="color:#50fa7b">NewUniIterator</span>(opt.Reverse))
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	iters = <span style="color:#8be9fd;font-style:italic">append</span>(iters, txn.db.levelController.<span style="color:#50fa7b">iterators</span>(<span style="color:#ff79c6">&amp;</span>opt)<span style="color:#ff79c6">...</span>)
</span></span><span style="display:flex;"><span>	res <span style="color:#ff79c6">:=</span> <span style="color:#ff79c6">&amp;</span>Iterator{
</span></span><span style="display:flex;"><span>		txn:    txn,
</span></span><span style="display:flex;"><span>		iitr:   table.<span style="color:#50fa7b">NewMergeIterator</span>(iters, opt.Reverse),
</span></span><span style="display:flex;"><span>		opt:    opt,
</span></span><span style="display:flex;"><span>		readTs: txn.readTs,
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>BadgerDB creates iterators across all the objects: all the memtables and all the SSTable files from Level0 to the last level, and returns an instance of <code>MergeIterator</code>. The <code>MergeIterator</code> organizes all the
iterators in the form of a binary tree.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-golang" data-lang="golang"><span style="display:flex;"><span><span style="color:#6272a4">//Code ommitted
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span><span style="color:#8be9fd;font-style:italic">type</span> MergeIterator <span style="color:#8be9fd;font-style:italic">struct</span> {
</span></span><span style="display:flex;"><span>	left  node
</span></span><span style="display:flex;"><span>	right node
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">//y.Iterator is an interface that has various implementations like skiplist.NewUniIterator, MergeIterator
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span><span style="color:#8be9fd;font-style:italic">func</span> <span style="color:#50fa7b">NewMergeIterator</span>(iters []y.Iterator, reverse <span style="color:#8be9fd">bool</span>) y.Iterator {
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">switch</span> <span style="color:#8be9fd;font-style:italic">len</span>(iters) {
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">case</span> <span style="color:#bd93f9">0</span>:
</span></span><span style="display:flex;"><span>		<span style="color:#ff79c6">return</span> <span style="color:#ff79c6">nil</span>
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">case</span> <span style="color:#bd93f9">1</span>:
</span></span><span style="display:flex;"><span>		<span style="color:#ff79c6">return</span> iters[<span style="color:#bd93f9">0</span>]
</span></span><span style="display:flex;"><span>	<span style="color:#ff79c6">case</span> <span style="color:#bd93f9">2</span>:
</span></span><span style="display:flex;"><span>		mi <span style="color:#ff79c6">:=</span> <span style="color:#ff79c6">&amp;</span>MergeIterator{
</span></span><span style="display:flex;"><span>			reverse: reverse,
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>		<span style="color:#6272a4">//When we are left with 2 iterators, set the left and the right node of MergeIterator
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>		mi.left.<span style="color:#50fa7b">setIterator</span>(iters[<span style="color:#bd93f9">0</span>])
</span></span><span style="display:flex;"><span>		mi.right.<span style="color:#50fa7b">setIterator</span>(iters[<span style="color:#bd93f9">1</span>])
</span></span><span style="display:flex;"><span>		mi.small = <span style="color:#ff79c6">&amp;</span>mi.left
</span></span><span style="display:flex;"><span>		<span style="color:#ff79c6">return</span> mi
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	mid <span style="color:#ff79c6">:=</span> <span style="color:#8be9fd;font-style:italic">len</span>(iters) <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">2</span>
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>	<span style="color:#6272a4">//Recursive call to arrange the iterators from 0 to mid-1, and then mid to the last index
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>	<span style="color:#ff79c6">return</span> <span style="color:#50fa7b">NewMergeIterator</span>(
</span></span><span style="display:flex;"><span>		[]y.Iterator{
</span></span><span style="display:flex;"><span>			<span style="color:#50fa7b">NewMergeIterator</span>(iters[:mid], reverse),
</span></span><span style="display:flex;"><span>			<span style="color:#50fa7b">NewMergeIterator</span>(iters[mid:], reverse),
</span></span><span style="display:flex;"><span>		}, reverse)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p><code>Seek</code> by design is a recursive operation (imagine it to be a binary tree traversal). Each iterator may find some value for the key. (The same key may be present in the active memtable and in one SSTable.)
So, <code>mi.fix()</code> resolves the key that will be returned from the <code>MergeIterator</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-golang" data-lang="golang"><span style="display:flex;"><span><span style="color:#6272a4">//Code ommitted
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span><span style="color:#8be9fd;font-style:italic">func</span> (mi <span style="color:#ff79c6">*</span>MergeIterator) <span style="color:#50fa7b">Seek</span>(key []<span style="color:#8be9fd">byte</span>) {
</span></span><span style="display:flex;"><span>	mi.left.<span style="color:#50fa7b">seek</span>(key)
</span></span><span style="display:flex;"><span>	mi.right.<span style="color:#50fa7b">seek</span>(key)
</span></span><span style="display:flex;"><span>	mi.<span style="color:#50fa7b">fix</span>()
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>MergerIterator is available <a href="https://github.com/dgraph-io/badger/blob/main/table/merge_iterator.go" target="_blank" rel="noopener">here</a>
.</p>
<h3 id="conclusion">Conclusion</h3>
<p>We have finally reached here :).</p>
<p>LSM-tree based storage engines typically include the following data structures:</p>
<ol>
<li>On-disk log file (WAL) to persist the writes.</li>
<li>In-memory memtable(s).</li>
<li>On-disk files organized in levels.</li>
</ol>
<p>LSM-trees offer higher write throughput because the writes are always sequential in nature, but reads are not so great because LSM-trees may have to scan multiple files or portions of multiple files.
One idea to improve the reads in LSM-trees is to reduce the size of SSTable files and cache some layers of SSTables.</p>
<p>When designing a storage engine for SSDs, we should consider SSD characteristics including:</p>
<ol>
<li>SSDs can wear out through repeated writes, the high write amplification in LSM-trees can significantly reduce the device lifetime.</li>
<li>SSDs offer a large degree of internal parallelism</li>
</ol>
<p>The core ideas of WiscKey include: separating values from keys in the LSM-tree to reduce write amplification and leveraging the parallel IO characteristic of SSD.</p>
<p>I hope the article was worth your time. Feel free to share the feedback.</p>
<h3 id="mention">Mention</h3>
<p>Thank you, <a href="https://github.com/unmeshjoshi" target="_blank" rel="noopener">Unmesh Joshi</a>
 for reviewing the article and providing feedback.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf" target="_blank" rel="noopener">WiscKey</a>
</li>
<li><a href="https://segmentfault.com/a/1190000041198407/en" target="_blank" rel="noopener">LSM-tree</a>
</li>
<li><a href="https://kt.academy/article/pmem-introducing-persistent-memory" target="_blank" rel="noopener">Introducing persistent memory</a>
</li>
<li><a href="https://github.com/dgraph-io/badger" target="_blank" rel="noopener">BadgerDB</a>
</li>
</ul>

  </article>
<div class="tag-list-container">
    <div class="tag-list">
        
        <a class="button" href="">
            <p class="tag"><i class="fa fa-fw fa-tag"></i>Storage engine</p>
        </a>
        
        <a class="button" href="">
            <p class="tag"><i class="fa fa-fw fa-tag"></i>LSM-tree</p>
        </a>
        
        <a class="button" href="">
            <p class="tag"><i class="fa fa-fw fa-tag"></i>WiscKey</p>
        </a>
        
        <a class="button" href="">
            <p class="tag"><i class="fa fa-fw fa-tag"></i>SSD-conscious</p>
        </a>
        
        <a class="button" href="">
            <p class="tag"><i class="fa fa-fw fa-tag"></i>BadgerDb</p>
        </a>
        
    </div>
</div>



<div class="px-2 mb-2">
  
  <script src="https://giscus.app/client.js"
    data-repo="SarthakMakhija/tech-lessons-comments"
    data-repo-id="R_kgDOJHu3mA"
    data-category="Announcements"
    data-category-id="DIC_kwDOJHu3mM4CUxhS"
    data-mapping="og:title"
    data-strict="0"
    data-reactions-enabled="1"
    data-emit-metadata="0"
    data-input-position="bottom"
    data-theme="light"
    data-lang="en"
    crossorigin="anonymous"
    async>
  </script>
  
</div>



    </main><footer class="container p-6 mx-auto flex justify-between items-center">
  <span></span>

  <span class="text-base font-thin">
    
    tech-lessons.in © 2020 / Powered by  <a class="font-bold" target="_blank" href="https://gohugo.io/">Hugo</a>
    
  </span>

  <span onclick="window.scrollTo({top: 0, behavior: 'smooth'})" class="p-1 cursor-pointer">
    <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5"
      stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M18 15l-6 -6l-6 6h12" />
    </svg>
  </span>
</footer>

<div class="search-ui absolute top-0 left-0 w-full h-full bg-white dark:bg-gray-800 hidden">
  <div class="container max-w-3xl mx-auto p-12">
    <div class="relative">
      <div class="my-4 text-center text-2xl font-bold">Search</div>

      <span class="p-2 absolute right-0 top-0 cursor-pointer close-search">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5"
          stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <line x1="18" y1="6" x2="6" y2="18" />
          <line x1="6" y1="6" x2="18" y2="18" />
        </svg>
      </span>
    </div>

    <input type="search" class="py-2 px-3 w-full dark:text-black border dark:border-transparent"
      placeholder="Enter search query" />

    <div class="search-results text-lg font-medium my-4 hidden">Results</div>
    <ul class="search-list my-2">

    </ul>

    <div class="no-results text-center my-8 hidden">
      <div class="text-xl font-semibold mb-2">No results found</div>
      <p class="font-light text-sm">Try adjusting your search query</p>
    </div>
  </div>
</div>





<script src="//localhost:1313/js/scripts.min.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-9KKTKFQ2CM"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-9KKTKFQ2CM');
        }
      </script>





<script>
  const mobileMenuButton = document.querySelector('.mobile-menu-button')
  const mobileMenu = document.querySelector('.mobile-menu')
  function toggleMenu() {
    mobileMenu.classList.toggle('hidden');
    mobileMenu.classList.toggle('flex');
  }
  if(mobileMenu && mobileMenuButton){
    mobileMenuButton.addEventListener('click', toggleMenu)
  }
</script>
</body>
</html>
